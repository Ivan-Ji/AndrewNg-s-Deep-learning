<!-- TOC -->

- [3. Seq2Seq 模型](#3-seq2seq-模型)
    - [3.1 基本模型](#31-基本模型)
        - [文本翻译模型](#文本翻译模型)
        - [图像描述(image captioning)`image2seq`](#图像描述image-captioningimage2seq)
    - [3.2 选择最可能的句子（ 贪心搜索，Greedy Search）](#32-选择最可能的句子-贪心搜索greedy-search)
        - [贪心搜索](#贪心搜索)
    - [3.3 选择最可能的句子（ 集束搜索，又称为定向搜索， Beam Search）](#33-选择最可能的句子-集束搜索又称为定向搜索-beam-search)
        - [集束搜索的方法](#集束搜索的方法)
    - [3.4 改善集束搜索](#34-改善集束搜索)
        - [3.4.1 长度归一化](#341-长度归一化)
        - [3.4.2 如何选择 B](#342-如何选择-b)
    - [3.5 beam search 的误差分析](#35-beam-search-的误差分析)
    - [3.6 Bleu 得分](#36-bleu-得分)
        - [3.6.1 对单个单词进行评估](#361-对单个单词进行评估)
        - [3.6.2 对二元词组进行评估](#362-对二元词组进行评估)
        - [3.6.3 公式化 Bleu 的计算](#363-公式化-bleu-的计算)
        - [3.6.4 Bleu 的细节](#364-bleu-的细节)
    - [3.7 注意力模型](#37-注意力模型)
        - [3.7.1 使用注意力模型的原因](#371-使用注意力模型的原因)
        - [3.7.2 注意力模型的直观理解](#372-注意力模型的直观理解)
        - [3.7.3 注意力模型的深入理解（公式）](#373-注意力模型的深入理解公式)
            - [encoder 端](#encoder-端)
            - [decoder 端](#decoder-端)
            - [注意力模型的缺点](#注意力模型的缺点)
    - [3.8 语音识别](#38-语音识别)
        - [如何构建语音识别系统](#如何构建语音识别系统)
    - [3.9 触发字检测](#39-触发字检测)

<!-- /TOC -->


# 3. Seq2Seq 模型

## 3.1 基本模型

### 文本翻译模型

比如你想通过输入一个法语句子来将它翻译成一个英语句子，如下图，seq2seq模型，用 $x^{< 1 >}, x^{< 2 >}, x^{< 3 >}, x^{< 4 >}, x^{< 5 >}$ 来表示输入句子的单词，然后用 $y^{< 1 >}, y^{< 2 >}, y^{< 3 >}, y^{< 4 >}, y^{< 5 >}, y^{< 6 >}$来表示输出的句子的单词，

|![image](3.1-1%20基础模型之文本翻译模型.png) |
|----|

如何训练一个新的网络，来表示输入序列 $x$ 和输出序列 $y$ 呢？

首先，我们先建立一个网络，这个网络叫做编码网络`encoder`，它是一个 RNN 的结构，RNN 的单元可以是 GRU，也可以是 LSTM，每次只向该网络中输入一个法语单词，将输入序列接收完毕后，这个 RNN 网络会输出一个向量来代表这个输入序列。之后，你可以建立一个解码网络`decoder`，它以编码网络的输出作为输入，之后它可以被训练为每次输出一个翻译后的单词，一直到它输出序列的结尾或者句子的结尾标记，这个解码网络的工作就结束了。

### 图像描述(image captioning)`image2seq`

如下图，给出一张图片，比如这张猫的图片，它能自动地输出该图片的描述，一只猫坐在椅子上。如何训练出这样的网络通过输出图像来输出描述？

|![image](3.1-2%20基础模型之图片描述模型.png) |
|----|

方法如下：将图片输入到卷积神经网络中，比如一个预训练的 AlexNet 结构，然后让其学习图片的编码，或者学习图片的一系列特征，如果去掉最后的 softmax 单元（用于图片的分类），这个预训练的 AlexNet 结构会输出一个 4096 维的特征向量，向量表示的是这张图片的描述，所以这个预训练网络可以是图像的编码网络，接着你可以把这个向量输入到 RNN 中，RNN 要做的就是生成图像的描述，每次生成一个单词，让网络输出文本序列。

## 3.2 选择最可能的句子（ 贪心搜索，Greedy Search）

通过`encoder-decoder`的 RNN，会将输入的法语句子翻译成英语句子。decoder 输出单词的过程与语言模型生成序列类似，但是语言模型生成的序列是随机的，而机器翻译中生成的序列需要依据输入的语言，给出最好的翻译，是有条件的，因此称之为`条件语言模型`，即在`x`作为输入语句的条件下，生成输出语句`y`的语言模型。

但是对同一句法语的翻译可能会有多个分布，机器翻译追求的是精准，因此并不是从得到的分布中随机取样，而是要选出最好的最可能的翻译句子，即使得以下的条件概率最大化：

$$\underset{y^{< 1 >},...,y^{< T_y >}}{arg\,\,max} P(y^{< 1 >},...,y^{< T_y >}|x)$$

其中，x 是输入的序列，y 是输出的序列。

### 贪心搜索

要选出最优的结果，你可能会想到 **贪心搜索** 。什么是贪心搜索呢？*首先选出最优的第一个词，在选出了第一个词的基础之上，再选出最优的第二个词，以此类推。* 即一次挑选一个合适的词

但是贪心搜索在机器翻译中并不合适，机器翻译模型要做的是一次性挑选出整个输出序列，使得输出序列整体的概率最大化。比如下面两个句子，显然第一句比第二句翻译得更好，因为第一个更简洁：

`Jane is visiting Africa in September`

`Jane is going to be visiting Africa in September`

**贪心搜索的缺点** ：

1. 若按照贪心算法，当选择好前两个词`jane is`之后根据贪心算法，第三个词会是`going`最优，因此就会给出第二个句子，但是整个句子的条件概率并没有最大化。
2. 计算量大，假设有 10000 个词，要生成 10 个词的句子，那么就是去计算 10000 的 10 次方。

因此可以使用一种近似的搜索算法，挑出合适的句子并使之条件概率最大化，叫做束搜索算法`beam search algrithm`。下一节中介绍。

## 3.3 选择最可能的句子（ 集束搜索，又称为定向搜索， Beam Search）

### 集束搜索的方法

1. 选出翻译后的第一个词。下图包含了翻译语言所需要的 10000 个词。与贪心搜索不同，集束搜索会考虑多个单词选择，将选择数量设为参数 B （称为集束宽，Beam width），这里令 $B=3$ 。首先在 decoder 端的第一个输出，是在所有词库中选择出概率最大的 3 个词做为起始词。即 $P(y^{<1>}|x)$ 最大，比如选出如下 3 个词：

    |![iamge](3.3-1%20集束搜索方法之全词列表10000.png) |
    |----|

2. 针对每个起始词，都在decoder端的第二个时刻输出一个所有词库里的最优词，使该词与第一个词的联合条件概率最大,即p(y<1>,y<2>|x)最大,该概率可以计算得到： $P(y^{<1>},y^{<2>}|x)=P(y^{<1>}|x)*P(y^{<2>}|x,y^{<1>})$ 。比如，

   * 第一个词为`in`时，第二最好的词是`september`;
   * 第一个词为`jane`时，第二最好的词是`is`;
   * 第一个词为`September`时，第二最好的词是`XXX`;

    于是总共需要计算3*10000词，然后对这第二轮的30000个词进行评估选出概率最大的3个，这3个词不一定是要分别来自3个decoder输出，可以来自同一个。比如概率最大的是in–>september，第二大是jane–>is，第三大是jane–>visit，以september开头的并没有入选。于是beam search会将这三组词保存在内存中。于是原来有3种起始词，现在只剩 2 种了。

    |![image](3.3-2%20集束搜索方法之筛选第二个词.png) |
    |----|

3. 根据第二步生成3种情况，继续寻找联合条件概率最好的第三个词。后面也是同样的套路，每次寻找一个词，但获取出最有可能的 3 组，直到最后遇到句子的终止词，选出最优的一个句子。
4. 句子结束时会有一个终止符号 `<EOS>`

**注意** ： B=1 时等同于贪婪搜索。但假如令B>1，往往会找到比贪婪算法更优的结果。

## 3.4 改善集束搜索

### 3.4.1 长度归一化

上文介绍的集束搜索就是对下面的条件概率最大化：
$$arg\,\,\underset{y}{max}\prod_{t=1}^{T_y}P(y^{< t >}|x,y^{<1>},...,y^{< t-1 >})$$

以上公式的乘积其实就等于 $P(y^{<1>},...,y^{< T >}|x)$ 。但这样计算有很大 **缺点** ：因为每一项的概率 `p<1`，假设这个要预测的序列很长，就会有很多概率 P 相乘，会得到很小很小的数字，导致电脑的浮点不能精确得储存。因此，实际中会将上述乘积公式变成对数求和的模式：
$$arg\,\,\underset{y}{max}\sum_{t=1}^{T_y}log\,P(y^{< t >}|x,y^{<1>},...,y^{< t-1 >})$$

但这还有一个 **缺点** ，当序列很长的时候，每一项的概率值很小，取对数之后就为负，所有log项相加就会越来越负，使得模型更倾向于输出较短的句子。因此，对公式做调整，不去求对数和的最大值，而是去求 log 项的均值：
$$\frac{1}{T_y}\sum_{t=1}^{T_y}log\,P(y^{< t >}|x,y^{<1>},...,y^{< t-1 >})$$

此时 $T_y$ 是句子的长度，即用长度做归一化。为了使其更柔和，往往会在 $T_y$ 上放一个指数 $α$：
$$\frac{1}{T_y^α}\sum_{t=1}^{T_y}log\,P(y^{< t >}|x,y^{<1>},...,y^{< t-1 >})$$

当 $α=1$ 时等价于用序列长度去归一化，当 $α=0$ 时等价于完全没有归一化，而`0<a<1`则是在归一化与不归一化之间寻找一个合适的位置。a是一个超参数，需要在实验中调整大小来获得最好的结果。

### 3.4.2 如何选择 B

B 越大，你考虑的范围就越大，找到的句子可能越好，从而计算量也越大。
在大部分企业应用中，一般会使用 B=10 左右，设为 100 已经很大了；但是在科研中，往往为了得到最最最优秀的结果发论文，会设置 B=1000 或者 3000

**总结**：与深度优先算法 DFS 、广度优先算法 BFS 这类精确搜索算法不同，集束搜索虽然运行快，但是不能保证找到精确的 $P(y|x)$ 的最大值。

## 3.5 beam search 的误差分析

beam search 是一种近似搜索算法，也被称做启发式搜索算法。它不总是输出可能性最大的句子，它只会根据认为设定的 B ，去选取前B种可能。那么如果 beam search 算法出现错误怎么办呢？下面介绍下误差分析与 beam search 算法是如何互相起作用,使我们发现到底是 beam search 算法出现了错误还是RNN 模型出现了错误。

还是引用之前的法语：`Jane visite l'Afrique en septembre.`，把它翻译成正确的英语应该是：`Jane visits Africa in September.`，但是模型通过训练后给出的翻译是：`Jane visited Africa last September.`。 经过比较发现，模型翻译改变了原句的含义（发生了误差），这个时候就要去找原因了，到底是 beam search 处理不当导致的错误，还是说 RNN 本身有与训练集太少等原因导致的错误呢？

这个时候我们会想到，无论是谁的错，反正我就增大B，或者增多训练样本就行。但是就算这样也不一定能得到你想要的结果。回顾翻译模型RNN的结构，这里其实是`encoder-decoder`结构加上了 `beam search`算法

|![image](3.5-1%20beam%20search的误差分析之机器翻译的RNN结构.png) |
|----|

分别计算翻译对的句子（ 上述正确的翻译用 $y^*$ 表示）和翻译错的句子（ 上述有误差的翻译用 $\hat{y}$ 表示）的条件概率，即比较 $p(y^*|x)$ 与 $p(\hat{y}|x)$ 的大小，从而来判断错误的预测应该归咎于 RNN 还是 beam search ：

1. 若 $p(y^*|x)>p(\hat{y}|x)$ ，则说明 RNN 并没有错，是 beam search 的错，就需要调整集束宽 B 的大小
2. 若 $p(y^*|x)≤p(\hat{y}|x)$ ，则说明 beam search 并没有错，是 RNN 的错。通过正则化、增加训练数据、更换不同的网络结构等方式。

对所有预测出错的句子都进行如上计算，并统计出有多少比例是归咎与 beam search ，有多少比例是归咎于 RNN 。

## 3.6 Bleu 得分

从一种语言翻译成另一种语言，自然没有完全的一个标准答案，翻译模型有时可能会输出多个都很正确的结果，那么此时要如何评估一个机器翻译系统呢？通常，会使用`bleu score`来评估。

`French: Le chat est sur le tapis.`

`Reference 1: The cat is on the mat.`

`Reference 2: There is a cat on the mat.`

将上述法语进行翻译，两句人工翻译都是准确的，此时对于机器翻译给出的句子们，会给每个句子都计算一个`Bleu`得分来进行比较。评估的依据是如果翻译的句子离人工翻译的结果越接近，则`Bleu score`应越高。（Bleu：双语评估替补`bilingual evaluation understudy`)

### 3.6.1 对单个单词进行评估

`MT output: the the the the the the the.`

假设机器给出的翻译是上述句子，就会是个极差的翻译。

评估翻译的准确性`precision`。假设机器翻译的句子中的单词出现在了任意一句人工翻译句子中，则得一分。那么由于`the`出现在了人工翻译中，于是机器翻译句子总共7个单词，出现在人工翻译中的单词有7个，`precision=2/7`。这显然不符合常理，因为给这个句子打0分都不足为过。

于是，经过改进，分子的上限是该单词在所有人工翻译句子中出现次数的最大值，`the`在`reference 1`中出现 2 次，在`reference 2`中出现了 1 次，于是上限是 2 ，因此`modified precision=2/7`。分母是机器翻译后单词`the`的频率，分子是单词`the`在人工翻译中出现的最大次数。

### 3.6.2 对二元词组进行评估

除了对单个词计算`precision`，还可以对二元词组（即相邻的两个单词）计算`precision`。仍然是上面这个例子，这一次模型给出的翻译稍微好一丢丢了：

`MT output: the cat the cat on the mat.`

获取这个句子出现的所有二元词组，并分别计算每个词组出现的次数，同时计算这些词组在人工翻译句子中出现的最大次数（分别是以下3列表示）：

||MT count|Reference count_clip|
|----|----|----|
|the cat|2|1|
|cat the|1|0|
|cat on |1|1|
|on the |1|1|
|the mat|1|1|
|count_sum|6|4|

将第三列的和除以第二列的和，得到的分值就是基于二元组的分值：`4/6`

### 3.6.3 公式化 Bleu 的计算

将上面的过程用公式表示：

* 一元评估：

    $$P_1=\frac{\sum_{unigram\in\hat{y}}count_{clip}(unigram)}{\sum_{unigram\in\hat{y}}count(unigram)}$$

* n 元评估：

    $$P_n=\frac{\sum_{n-gram\in\hat{y}}count_{clip}(n-gram)}{\sum_{n-gram\in\hat{y}}count(n-gram)}$$

可见，如果机器翻译的句子和任何一句人工给出的翻译一模一样，那么以上得分将都为 1 。

### 3.6.4 Bleu 的细节

上面都在讲precision,那么说好的Bleu score呢？
根据以上的precision来构造最终的blue score。用`Pn`表示`Bleu score on n-grams only`。分别计算出机器翻译的句子的`P1,P2,P3,P4`；然后求均值得到平均的`Bleu score`再取幂，即 $exp(\frac{1}{4}\sum_{n=1}^4logP_n)$ 。但这还不算最终的`Bleu score`，需要再给均值项上乘以一个简单惩罚因子`BP(brevity penalty)`，顾名思义，即给较短的句子给予惩罚：

$BP=\left\{\begin{matrix}1,\,\,\,if\,MT\_output\_length>reference\_output\_length\\ exp(1-MT\_output\_length/reference\_output\_length).\,\,\,otherwise\end{matrix}\right.$

BP的原理是，如果翻译的句子越短，那么越有可能具备较高的`bleu score`，但是越短的句子并不是越好，较高的`bleu score`会误导我们的选择，因此需要给短句一个惩罚，使它的`bleu score`均值乘以一个`0-1`之间的系数。

所以最终的 Bleu 得分就是 $Bleu\, Score=BP*exp(\frac{1}{N}\sum_{n=1}^NlogP_n)$ 。

BLEU 得分常常用于机器翻译、图像描述、文本生成等，但是语音识别不会用到该得分。

## 3.7 注意力模型

### 3.7.1 使用注意力模型的原因

之前的翻译案例都是一句很短的话，使用单纯到`encoder-decoder RNN`可以取得较高到`Bleu Score`。对于一大段文字，人工翻译一般每次阅读并翻译一小部分。因为难以记忆，很难每次将一大段文字一口气翻译完。同理，用 `Seq2Seq` 模型建立的翻译系统对于长句子，Blue 得分会随着输入序列长度的增加而降低。我们也并不希望神经网络每次去“记忆”很长一段文字，而是想让它像人工翻译一样，一点一点翻译出句子，在长句中取得与短句同样好的表现。因此，注意力模型（Attention Model）被提出。目前，其思想已经成为深度学习领域中最有影响力的思想之一。

### 3.7.2 注意力模型的直观理解

注意力机制虽然源于机器翻译，但也广泛推广到了其他领域。为了讲解方便，使用下列短句来做演示：

`Jane visite l'Afrique en septembre.`

这里我们使用一个双向的 RNN （BRNN）用来计算输入特征，每一个时刻的输入是一个法语单词，属于`encoder`端，`decoder`端是另一个 RNN 。

这里使用`S`表示输出层`decoder`端。0 时刻的状态记为`S<0>`，第一个时刻`S<1>`的输出应该是`jane`。为了使输出更准确，需要去回看一下输入的第一个单词或者与第一个单词相邻的单词。这个回看的过程就是注意力的过程，因此用`a<1,1>`表示第一个输出需要给第一个输入多少注意力，翻译的过程不是词的一对一，因此可能第二个输入也会影响到第一个输出，用`a<1,2>`表示预测第一个词需要给多少注意力给第二个输入的单词。以此类推，也会有`a<1,3>`。**最后** ，所有的注意力信息用`c`表示，输入给第一时刻的状态`S<1>`。过程如下图所示：

|![image](3.7-1%20注意力模型之注意力过程示意图1.png) |
|----|

同理，`S<2>`也会有相应的注意力信息`C`输入，同时它原来的两个输入也是存在的：上一个时刻的输出与上一个时刻的隐层信息（记忆）。剩下的词以此类推，直到输出`<EOS>`则完成翻译。如下图所示：

|![image](3.7-2%20注意力模型之注意力过程示意图2.png) |
|----|

### 3.7.3 注意力模型的深入理解（公式）

对注意力模型有了一个大概的了解之后，现在来深入讲一讲其运行机制。

#### encoder 端

|![image](3.7-3%20注意力模型之encoder端示意图.png) |
|----|

由于是双向 RNN，因此每个时刻都有两个激活值（前向、后向，注意不是反向），为了表示方便，我们把这两个激活值合起来表示成`a<t'>`:

$$a^{<t'>}=(\overrightarrow{a}^{<t'>},\overleftarrow{a}^{<t'>})$$

#### decoder 端

在`decoder`端是一个单向的`RNN`，时刻`t=1`时，有两个输入：零时刻状态`S<0>`和注意力信息`C`，如下图所示：

|![image](3.7-4%20注意力模型之decoder端示意图.png) |
|----|

**注意力信息** `C`来自于输入端的注意力信息`a<1,1>, a<1,2>, a<1,3>`的和：

|![image](3.7-5%20注意力模型之注意力信息累加图.png) |
|----|

将所有`a<1,i>`加起来应等于`1`。`C<1>`的计算公式如下：

* $a^{<t'>}=(\overrightarrow{a}^{<t'>},\overleftarrow{a}^{<t'>})$
* $\sum_{t'}\alpha^{<1,t'>}=1$
* $C^{<1>}=\sum_{t'}\alpha^{<1,t'>}a^{<t'>}$

将上述`c<1>`计算公式中的`1`推广成其他预测单词，这里用`t`表示。`α<t,t'>`代表着预测的单词`t`需要多少注意力给输入单词`t'`的激活项。那么`α<t,t'>`如何计算呢？使用`softmax`，公式如下：

* $\alpha^{<t, \,t'>}=\frac{exp(e^{<t,t'>})}{\sum_{t'=1}^{T_x}e^{<t,t'>}}$

之所以用`exp()`来表示，可以保证所有`a<t,t'>`求和能等于1。那么公式中的`e<t,t'>`又是咋来的呢？可以用一个如下的小神经网络训练出来，如下图所示。具体操作参考 [深度学习笔记——Attention Model（注意力模型）学习总结](https://blog.csdn.net/mpk_no1/article/details/72862348) 。

|![image](3.7-6%20注意力模型之神经网络训练参数.png) |
|----|

输入时`s<t-1>`上一时刻的激活值，`a<t'>`是该时刻对应的 encoder 端的激活值。

最后，注意力模型的参数 $\alpha^{<t,t'>}$ 可以可视化，类似共现矩阵，如下图所示：

|![image](3.7-7%20注意力模型之注意力参数可视化.png) |
|----|

#### 注意力模型的缺点

复杂度为 $O(n^3)$ 。如果输入的词有 $T_x$ 个，输出的词有 $T_y$ 个，则注意力模型系数共有 $T_x * T_y$ 个。因此这个算法有着三次方的消耗。不过在机器翻译上，输入与输出的句子大部分情况下都不会太长，因此三次方的消耗也还可以接受；但也有很多研究工作需要去尝试减少这样的消耗。

注意力模型也被用于`图片添加标题`、`标准化日期（序列转换）`等任务中

## 3.8 语音识别

AI领域最令人兴奋的发展之一就是seq2seq model，它使得语音识别的准确率大大提升了。那语音识别是什么？简单来说就是有一段音频`x`，任务是要自动生成对应的文本`y`

曾经有段时间，语音识别系统是通过音位`phonemes`来构建的，也就是人工设定的基本单元。但是现在有了seq2seq model之后，就不需要人为搞的基本单元了，而是可以直接构造一个系统：向系统输入音频片段，系统直接输出文本。不过要构建这个系统需要一个很大的训练数据集，可能长达300小时，3000小时，目前最好的商业系统已经训练了100000个小时了。

### 如何构建语音识别系统

1. 第一种方法：结构和机器翻译一样，不赘述。

    |![image](3.8-1%20语音识别之语音识别系统结构.png) |
    |----|
2. 第二种方法：使用 CTC 损失函数`CTC：Connectionist Temporal Classification`。假设输入的语音是`the quick brown fox`。首先构建一个RNN网络（实际中更复杂，这里先用一个简单的单向网络做示范）

    假设每秒音频可以提取出100个特征值，那么假设10秒的音频就有1000个特征值，那么输出值也有1000个，但是说出的话并没有这么多啊，那该怎么处理呢？方法很简单，只需要把`_`进行压缩即可，注意需要将`_`和空格区分开来，因为空格也是占一个字符的。

    |![image](3.8-2%20语音识别之CTC损失函数.png) |
    |----|

## 3.9 触发字检测

什么是触发字检测呢？假设你买了一个天猫精灵，你每次要跟他说话之前，都必须先喊一下`天猫精灵`触发他启动，他才能去有意识得听你接下去讲的话。像这样的产品很多，最近比较流行的还有小米的音响，也需要具备`触发字检测`来唤醒。

这要怎么做呢？可以利用 RNN 甚至 attention 模型做成一个语音识别系统。

1. 先将音频转换成音谱特征`x1,x2…`，然后放入 RNN 中，当音频中出现了触发词时，则 RNN 的在该时刻的输出就为 1 ，否则为 0

2. 这个算法有很大缺点，就是它构建了一个很不平衡的训练集：0 的数量是 1 的数倍。有一个粗暴的解决方法，就是在识别了触发词之后，即某个时刻开始输出1之后，后面即使出现了非触发词，也标注为 1 ，这样就增多了 1 的比例。因为我们只需要识别出是否有触发词，从而判断是否唤醒，一旦识别到了1就行。
