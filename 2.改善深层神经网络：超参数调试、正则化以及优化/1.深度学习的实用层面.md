<!-- TOC -->

- [1.深度学习的实用层面（基本概念和方法）](#1深度学习的实用层面基本概念和方法)
    - [1.1 训练/验证/测试集`train/dev/test sets`](#11-训练验证测试集traindevtest-sets)
    - [1.2 偏差`Bias`/ 方差`Variance`](#12-偏差bias-方差variance)
    - [1.3 基本优化方法](#13-基本优化方法)
        - [注意](#注意)
    - [1.4 正则化及其作用原理](#14-正则化及其作用原理)
        - [1.4.1 `L1`正则化](#141-l1正则化)
        - [1.4.2 `L2`正则化](#142-l2正则化)
        - [为什么只对参数`W`正则化，而不对参数`b`也进行正则化呢](#为什么只对参数w正则化而不对参数b也进行正则化呢)
        - [神经网络下的`L2`正则化](#神经网络下的l2正则化)
        - [如何使用`佛罗贝尼乌斯范数`实现梯度下降呢](#如何使用佛罗贝尼乌斯范数实现梯度下降呢)
    - [1.5 正则化减少过拟合的原因](#15-正则化减少过拟合的原因)
        - [为什么压缩L2范数可以减少过拟合呢](#为什么压缩l2范数可以减少过拟合呢)
        - [建议](#建议)
    - [1.6 `Dropout`正则化](#16-dropout正则化)
        - [1.6.1 `Dropout`的概念及实施方法](#161-dropout的概念及实施方法)
        - [概念](#概念)
        - [实施方法](#实施方法)
        - [如何在测试阶段训练代码](#如何在测试阶段训练代码)
        - [1.6.2 `Dropout`的原理](#162-dropout的原理)
        - [每一层的`keep-prob`参数可以不同](#每一层的keep-prob参数可以不同)
        - [总结](#总结)
    - [1.7 其他正则化方法](#17-其他正则化方法)
        - [1.7.1 数据扩增](#171-数据扩增)
            - [1.7.1.1 针对图片分类](#1711-针对图片分类)
            - [解决办法](#解决办法)
            - [1.7.1.2 图片中的字符识别](#1712-图片中的字符识别)
        - [1.7.2 `Early stopping`方法](#172-early-stopping方法)
            - [`early stopping`是怎么发挥作用的呢](#early-stopping是怎么发挥作用的呢)
    - [1.8 正则化输入](#18-正则化输入)
        - [归一化输入的两个步骤](#归一化输入的两个步骤)
        - [归一化输入的原因](#归一化输入的原因)
    - [1.9 梯度消失与梯度爆炸](#19-梯度消失与梯度爆炸)
    - [1.10 神经网络的权重初始化](#110-神经网络的权重初始化)
    - [1.11 梯度检验（确保反向传播的正确）](#111-梯度检验确保反向传播的正确)
        - [1.11.1 数值逼近`Numerical approximation of gradients`](#1111-数值逼近numerical-approximation-of-gradients)
        - [1.11.2 执行梯度检验](#1112-执行梯度检验)
        - [梯度检验的步骤`Grad check`](#梯度检验的步骤grad-check)
    - [1.12 梯度检验的补充](#112-梯度检验的补充)

<!-- /TOC -->

# 1.深度学习的实用层面（基本概念和方法）

## 1.1 训练/验证/测试集`train/dev/test sets`

在深度学习中，最重要的是拥有的数据量、输入特征的数量、使用`CPU`还是`GPU`、`CPU`和`GPU`的配置以及其他诸多因素。但应用型机器学习是一个高度迭代的过程：在项目启动时，有一个初步的想法，比如构建一个含有特定层数、隐藏单元数量或数据集个数的神经网络，然后写代码并尝试运行，通过运行和测试得到该神经网络或配置信息的运行结果。接着根据输出结果，重新完善自己的想法、改变策略，或为了找到更好的神经网络不断更新迭代自己的方案。该过程如下图所示：

|![image](1.1-1%20机器学习的迭代过程.png)|
|----|

循环该过程的效率是决定项目进展速度的一个关键因素，而创建高质量的数据集`训练集、验证集、测试集`也有助于提高循环效率。

如果有一组数据，将它分成几部分，一部分作为`训练集`，一部分作为`验证集dev set`，最后一部分作为`测试集`。将数据分为这几部分之后，就开始对训练集执行训练算法，通过验证集选择最好的模型。经过充分验证后，选定最终模型，就可以在测试集上进行评估。

在机器学习的小数据量时代，常见做法是将所有数据三七分（70%验证集、30%测试集）。如果没有明确设置验证集，也可以按照`60%训练集、20%验证集、20%测试集`来划分。如果数据量过于庞大（比如百万级别），验证集和测试集所占的比例会趋向于变得更小。因为验证集的功能就是为了检验哪种算法更有效，所以验证集要足够大才能评估不同的算法并判断哪种算法更有效。由于深度学习算法需要大量的训练数据，为了获取更大规模的数据集，可以采用一些特殊的策略（比如爬虫），但训练集数据与验证集和测试集数据有可能不是来自同一分布。在验证和测试时要确保验证集和测试集的数据来自同一分布（反例：公司使用网上精细的图片训练识别猫，用户自己上传相对模糊的猫的照片），原因是同一分布的数据会让机器学习算法变得更快。

在开始训练的时候，即使没有测试集也没关系，测试集的目的是对最终选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。因此，如果只有验证集、没有测试集，要做的就是在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，不再提供无偏性能评估。在机器学习中，如果只有训练集和验证集而没有独立的测试集，训练集依然被称为`训练集`，而验证集就被称为`测试集`（也可称为`训练验证集`），人们也只是在实际应用中把测试集当成`简单交叉验证集`使用，并没有实现该术语的功能，原因是把验证集数据过度拟合到了测试集中。

## 1.2 偏差`Bias`/ 方差`Variance`

偏差`bias`：偏差衡量了模型的预测值与实际值之间的偏离关系。通常在深度学习中，我们每一次训练迭代出来的新模型，都会拿训练数据进行预测，偏差就反应在预测值与实际值匹配度上，比如通常在keras运行中看到的准确度为96%，则说明是低偏差；反之，如果准确度只有70%，则说明是高偏差。

方差`variance`：方差描述的是训练数据在不同迭代阶段的训练模型中，预测值的变化波动情况（或称之为离散情况）。从数学角度看，可以理解为每个预测值与预测均值差的平方和的再求平均数。通常在深度学习训练中，初始阶段模型复杂度不高，为低方差；随着训练量加大，模型逐步拟合训练数据，复杂度开始变高，此时方差会逐渐变高。

误差`Error`:关于深度学习的`误差`，人们对偏差、方差的权衡研究尚浅，而深度学习的误差很少权衡两者，因此不作说明。一般来说，最优误差也被称为`贝叶斯误差`。具体讨论参考[深度学习基础系列（八）|偏差和方差](https://www.cnblogs.com/hutao722/p/9921788.html)

|![image](1.2-1%20方差、偏差靶心图.png)|
|----|

这是一张常见的靶心图。可以想象红色靶心表示为实际值，蓝色点集为预测值。在模型不断地训练迭代过程中，我们能碰到四种情况：

① 低偏差，低方差：这是训练的理想模型，此时蓝色点集基本落在靶心范围内，且数据离散程度小，基本在靶心范围内；

② 低偏差，高方差：这是深度学习面临的最大问题，过拟合了。也就是模型太贴合训练数据了，导致其泛化（或通用）能力差，若遇到测试集，则准确度下降的厉害；

③ 高偏差，低方差：这往往是训练的初始阶段；

④ 高偏差，高方差：这是训练最糟糕的情况，准确度差，数据的离散程度也差。

## 1.3 基本优化方法

初始模型训练完后，通过计算算法的偏差，可以更好的优化算法性能。

1. 如果偏差较高，尝试评估训练集数据的性能；如果偏差的确很高，甚至无法拟合训练集，则需要构建一个新网络（比如含有更多隐层或隐藏单元的网络），或者用更长的时间训练算法、再者去尝试更先进的优化算法。通常采用规模更大的网络会有帮助。延长训练时间没有什么好处，也没有什么坏处。在能扩大网络规模的情况下，如果网络足够大，通常可以很好拟合训练集。
2. 一旦偏差降低到可接受的数值，就需要计算方差。评估方差需查看验证集。方差高时，最好的办法就是采用更多的数据，如果能获得更多数据，会减小一定的方差。但有时候无法获得更多的数据，可以通过`正则化`的方式减少过拟合。PS：正则化会在本页`1.4`讲到。

有时候需要反复尝试，找到更合适的神经网络框架，同时减少方差和偏差，直到找到一个低偏差、低方差的框架。

### 注意

1. 高偏差和高方差是两种不同的情况，后续尝试的方法也可能完全不同。通常使用验证集来判断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。

2. 在机器学习的初期阶段，关于偏差、方差权衡的探讨屡见不鲜，原因是：尝试的方法有很多，比如可以增加偏差、减少方差；或者减少偏差、减少方差。但在深度学习的早期阶段，没有太多工具可以做到只减少偏差或方差，却不影响另外一方。但在当前的深度学习和大数据时代，只要持续训练一个更大的网络，以及准备更多数据，出现的情况也并非只有上述两种。假定只要`正则化`适度，通常构建一个更大的网络便可以在不影响方差的同时，减小偏差；而采用更多的数据通常可以在不过多影响偏差的同时，减少方差。

现在有工具可以做到在减小偏差或减小方差的同时，不对另一方产生过多影响。这就是深度学习对监督式学习有益的一个重要原因，也是现在不用过多关注如何平衡偏差和方差的一个重要原因。

正则化是一种非常实用的减少方差的方法，正则化时会出现偏差方差权衡的问题。在网络比较规范化的前提下，正则化对训练一个更大的网络几乎没有负面影响，而训练一个大型神经网络的主要代价也只是计算时间。有关`正则化`的介绍在下节会讲到。

## 1.4 正则化及其作用原理

如果神经网络过度拟合了数据，即存在高方差问题，首先想到的方法是`正则化`，另一种方法则是准备更多的数据。一般来说，可能无法获取更多的数据，或者获取数据的成本很高，此时正则化就发挥了帮助避免过拟合、减小网络误差的功能。正则项可以避免数据权值矩阵过大。具体作用为：

* L1正则化可以产生**稀疏权值矩阵**，即产生一个稀疏模型，可以用于特征选择
* L2正则化可以 **防止模型过拟合**（overfitting）；一定程度上，L1也可以防止过拟合

### 1.4.1 `L1`正则化

以[神经网络和深度学习](../1.神经网络和深度学习)中使用的`Logistic回归`为例：

求成本函数`J`的最小值 $\underset{W,b}{min}\,J(W,b)$，而`Logistic回归`的成本函数`J`的计算公式为：

$J(W,b)=\frac{1}{m}\sum_{i=1}^{m}L(\hat y^{(i)},y^{(i)})$

该成本函数的参数`W、b`包含一些训练数据和不同数据中个体预测的损失（其中`W`是一个多维度参数矢量，`b`是一个实数，即 $W\in \mathbb{R}^{n_{x}},b\in\mathbb{R}$ ）。

在成本函数中加入正则项 $\frac{\lambda}{m} \sum_ {j=1}^{n_{x}}|W| =\frac{\lambda}{m}\left \| W \right \|_{1}$ 。等号左边是非向量化的，等号右边是向量化的，指的是权值向量 $w$ 中 **各个元素的绝对值之和** 。这被称为参数`W`向量的`L1`范数，使用`1`的下标。`L1`正则项中的分母`m`和下面`L2`正则项中的分母`2m`是一个比例常项。

`λ`是正则化参数，通常使用验证集或交叉验证来配置该参数。尝试各种数据，寻找最好参数，要考虑训练集之间的权衡，把参数正常值设置为较小值，可以避免过拟合。因此`λ`是另外一个需要调整的超参数`Hyper Parameter`。在，为了不与`Python`里的关键字段冲突，一般把`λ`写成`lambd`，少一个`a`。此时`lambd`就代替了`lambda`正则化参数。

如果使用`L1`正则化，`W`最终会变得稀疏，也就是向量中有很多0。有观点认为这有利于 **压缩模型**，因为集合中参数均为0，存储该模型所占用的内存更少。但实际情况为，虽然`L1`正则化使 **模型变得稀疏**，却没有降低太多存储内存，这并不是`L1`正则化的目的，至少不是为了压缩模型。因此人们在训练网络时，越来越倾向于使用`L2`正则化。

### 1.4.2 `L2`正则化

`L2`正则化是最常见的正则化类型。还是以[神经网络和深度学习](/1.神经网络和深度学习)中使用的`Logistic回归`为例：

在`Logistic回归`中加入`L2`正则化，只需要添加参数`λ`(即正则化参数)，则成本函数的公式就变为：

$J(W,b)=\frac{1}{m}\sum_{i=1}^{m}L(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m} \left \| W \right \|_{2}^{2}$

其中 $\left \| W \right \|_{2}^{2}=\sum_ {j=1}^{n_{x}}w_{j}^{2}=W^{T}W$ ，指的是权值向量 $w$ 中 **各个元素的平方和然后再求平方根** 。`||W||`表示欧里几德范数，$W^{T}W$也表示向量参数`W`的欧里几德范数的平方。这种方法被称为`L2`正则化，因为这里用了欧里几德法线`||`，被称为向量参数`W`的`L2`范数。

### 为什么只对参数`W`正则化，而不对参数`b`也进行正则化呢

因为`W`通常是一个高维参数矢量，已经可以表达高偏差问题，而`W`可能含有很多参数，一般也不可能拟合所有参数，且`b`只是单个数字。所以`W`几乎涵盖所有参数，而不是`b`。当然，加了`b`之后也不会有太大影响（成本函数后面加 $\frac{\lambda}{2m} b^{2}$ ），毕竟`b`只是众多参数中的一个所以通常省略不计，当然加上也完全没问题。

### 神经网络下的`L2`正则化

神经网络下的成本函数的公式表示为：

$J(W^{[1]},b^{[1]}...W^{[L]},b^{[L]})=\frac{1}{m}\sum_{i=1}^{m} L(\hat y^{(i)},y^{(i)})$

加上正则项后，成本函数就变为了：

$J(W^{[1]},b^{[1]}...W^{[L]},b^{[L]})=\frac{1}{m}\sum_{i=1}^{m} L(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^{L}\left \| W^{[l]} \right \|^{2}$

正则项中的矩阵范数 $\left \| W^{[l]} \right \|^{2}=\sum_{i=1}^{n^{[l-1]}} \sum_{j=1}^{n^{[l]}}(W_{ij}^{[l]})^{2}$ 指的是`W`矩阵**各个元素的平方和**，其中`W`的维度为$(n^{[l-1]},n^{[l]})$。该矩阵范数被称为`佛罗贝尼乌斯范数 Frobenius`，因此矩阵范数可以表示为：$\left \| W^{[l]} \right \|^{2}_{F}$，下标为大写的`F`。由于线性代数的晦涩难懂，在这里就不把它称为`矩阵L2范数`，而是称为`佛罗贝尼乌斯范数`，这表示一个矩阵中**所有元素的平方和**。

### 如何使用`佛罗贝尼乌斯范数`实现梯度下降呢

1. 使用反向传播`backprop`计算`dW`的值。反向传播`backprop`会给出损失函数`J`对`W`的偏导数，即 $\frac{\partial J}{\partial W^{[l]}}$

2. 在`dW`中加入正则项。此时`dW`的公式就变为：

   $dW^{[l]}=\frac{\partial J}{\partial W^{[l]}}+\frac{\lambda}{m}W^{[l]}$

   新定义的`dW`中含有代价函数导数和相关参数，以及添加的正则项参数。

3. 更新 $W^{[l]}$ ，即使用公式 $W^{[l]}=W^{[l]}-\alpha dW^{[l]}$ 更新参数。此时更新的公式就变为：$W^{[l]}=W^{[l]}-\alpha dW^{[l]}= W^{[l]}-\frac{\alpha \lambda}{m} W^{[l]}-\alpha \frac{\partial J}{\partial W^{[l]}}$ 。该正则项说明，不论 $W^{[l]}$ 是什么，我们都尝试让它变得更小。实际上，这相当于给矩阵`W`乘以了 $(1-\frac{\alpha \lambda}{m})$ 倍的权重。因此L2正则化也被称为**权重衰减**，其原因是：`W`在**梯度更新的时候系数小于1**。

## 1.5 正则化减少过拟合的原因

引用`1.4.3`中的成本函数

$J(W^{[1]},b^{[1]}...W^{[L]},b^{[L]})=\frac{1}{m}\sum_{i=1}^{m} L(\hat y^{(i)},y^{(i)})$，

加入`L2`正则项之后成本函数变为：

$J(W^{[1]},b^{[1]}...W^{[L]},b^{[L]})=\frac{1}{m}\sum_{i=1}^{m} L(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^{L}\left \| W^{[l]} \right \|^{2}_{F}$

这里正则项的作用是：避免数据权值矩阵过大。

### 为什么压缩L2范数可以减少过拟合呢

1. 直观理解上，如果正则化`λ`设置的足够大，权重矩阵`W`被设置的接近 0（相当于把多隐藏单元的权重设为 0），基本上消除了这些隐藏单元的许多影响。在这种情况下，神经网络会被大大简化而变成一个很小的网络，小到如同一个逻辑回归单元，但深度却很大。这样也会使`低偏差、高方差`的过拟合变为`高偏差`状态。只是`λ`会存在一个中间值，于是会有一个`just right`的中间状态。
2. 直觉上我们认为大量隐藏单元被完全消除了，其实不然。实际上是该神经网络的所有隐藏单元依然存在，但是它们的影响变得更小了，因此神经网络变得简单了。实际操作过程中不会出现上述 `λ 足够大，W 接近于0` 情况，但可以尝试消除或减少许多隐藏单元的影响，最终使这个网络变得更简单，同时更不容易出现过拟合。在实际编程的过程中，也能看到一些方差减少的结果。
3. 使用具体模型进行理解。这里以`tanh`函数图像为例。

|![image](../1.神经网络和深度学习/3.4.2%20tanh函数图像.jpg)|
|----|

* 假设构建神经网络使用的是`tanh`激活函数，此时`g(z)=tanh(z)`。如果`z`只涉及少量参数同时`z`特别小，就可以利用`tanh`函数的线性状态；而当`z`非常大或非常小时，该函数的斜率就变得非常平缓，变成了非线性的状态。
* 由于`z=w*a+b`，如果`W`很小，`z`的值也会相对较小。因此这里可以利用`tanh`函数的线性状态。这样一来，每一层网络几乎都是线性的，。在 [3.5 神经网络需要非线性激活函数的原因](../1.神经网络和深度学习/3.浅层神经网络.md) 中讨论过，如果每一层神经网络都是线性的，则整个网络就是一个线性网络。即使是一个非常深的网络，因为具有线性激活函数的特征，最终也只能计算出线性函数。因此`L2`正则化不适用于非常复杂的决策，以及过度拟合数据集的非线性决策边界。
* 摒弃一个观点：当正则参数`λ`足够大，激活函数的参数会相对小。因为成本函数中的参数变大了

### 建议

在增加正则化项时，成本函数`J`就需要增加正则化项。此时如果使用梯度下降函数，在调试梯度下降时，其中一步就是把成本函数设计成这样一个函数（代表梯度下降的调幅数量的函数），可以看到，成本函数对于梯度下降的每个调幅都单调递减，此时成本函数`J`已经有了一个全新的定义。如果使用的是原本的成本函数，可能就看不到成本函数单调递减的现象。所以，为了调试梯度下降，务必使用增加正则化项之后的成本函数`J`，否则函数`J`可能不会再所有调幅范围内都单调递减。

详细讲解查看[为什么正则化可以减少过拟合？](https://mooc.study.163.com/learn/2001281003?from=study#/learn/content?type=detail&id=2001702116)

## 1.6 `Dropout`正则化

### 1.6.1 `Dropout`的概念及实施方法

| ![image](1.6.1%20dropout正则化示意图1.png)| ![image](1.6.1%20dropout正则化示意图2.png)| ![image](1.6.1%20dropout正则化示意图3.png)|
|----|----|----|
|图1 过拟合神经网络图|图2 `Dropout`正则化时的示意图|图3 `Dropout`结果的示意图|

### 概念

1. 假设图1是一个存在过拟合的神经网络。输入是其中一个训练样本。
2. 对`图1`进行`dropout`正则化时，`dropout`会遍历网络的每一层，并设置消除神经网络中节点的概率。这里假设每一层的每个节点都以抛硬币的方式设置概率，每个节点得以保留或消除的概率都是`0.5`。设置好概率后，就会消除一些节点，如`图2`所示。
3. 消除节点之后，删掉从该节点进出的连线。最终可以得到一个节点更少、规模更小的网络，如`图3`所示。然后再用反向传播`backprop`的方法进行训练。
4. 对于其他训练样本，也可以使用抛硬币的方式设置概率，保留一类节点集合，删除其他类型的节点集合。对于每一个训练样本，都会采用一个精简后的神经网络来训练，

### 实施方法

实施方法有好几种，但 **反向随机失活**`inverted dropout`是最常用的，就是。出于完整性考虑，将用一个三层`L=3`的网络来举例说明。这里假设在第三层中实施`dropout`。

1. 首先定义向量`d`，`d3`表示一个三层的`dropout`向量。参数都是`a3.shape`。
2. 判断`d3`是否小于某个数，这里用`keep-prob`表示，代表`保留某个隐藏单元的概率(keep probability)`。`keep-prob`是一个具体数字，上一小节的概念里它是`0.5`，在本节里设置为`0.8`，也就意味着消除任意一个隐藏单元的概率为`0.2`。

   这里`d3`的作用是生成随机矩阵，如果对`a3`进行因式分解，效果也是一样的。`d3`是一个矩阵，每个样本和每个隐藏单元在`d3`中对应值为1的概率都是`0.8`，对应值为0的概率都是`0.2`。随机数字小于`0.8`，就有`0.8`的概率等于`1`或等于`True`，有`0.2`的概率等于`0`。
3. 从第三层中获取激活函数，这里称之为`a3`。`a3`含有要计算的激活函数。把`a3`和`d3`相乘，得到新的`a3`，即 `a3=a3*d3`。

   **作用**：过滤`d3`中所有等于0的元素，而`d3`各个元素等于0的概率只有`20%`，乘法运算最终把`d3`中相应元素归零。`d3`是一个布尔型数组，值为`true`和`false`，而不是`0`和`1`。但在`Python`的乘法运算中会把`true`和`false`翻译成`1`和`0`。
4. 向外扩展`a3`。使用`a3`除以参数`keep-prob`，也就是`0.8`。除以参数`keep-prob`的原因举例说明：

    假设第三隐藏层上有50个单元或神经元，通过因式分解将`a3`拆分为`50*m`维的，所以在一维上`a3=50`。而保留和删除这些神经元的概率分别是`80%`和`20%`，也就意味着最后被删除或归零的单元平均有10个。此时有公式 $z^{[4]}=w^{[4]}a^{[3]}+b^{[4]}$。因为预期`a3`减少了`20%`，即`a3`中有`20%`的元素被归零。为了不影响$z^{[4]}$的期望值，需要执行$\frac{w^{[4]}a^{[3]}}{0.8}$，这会修正或弥补所需的、已经被删除的`20%`。这也不会改变$a^{[3]}$的期望值。

具体计算代码如下所示：

```text
import numpy as np

keep-prob =0.8
d3 = (np.random.rand(a3.shape[0], a3.shape[1])   < keep-prob)
a3 = np.multiply(a3, d3)            # a3 *= d3
a3 /= keep-prob                     # 反向随机失活的dropout方法，通过除以keep-prob，确保a3的期望值不变
```

### 如何在测试阶段训练代码

在测试阶段，会给出`x`或者想要预测的变量，使用的是标准计数法。

$no\,\, dropout:\\\,\,\,\,\,\,\, Z^{[1]}=W^{[1]}A^{[0]}+b^{[1]}\\\,\,\,\,\,\,\,  a^{[1]}=g^{[1]}(Z^{[1]})\\\,\,\,\,\,\,\,  ......\\\,\,\,\,\,\,\,  get\,\, \hat y$

在测试阶段，没有使用`dropout`，自然也不用抛硬币来决定`失活概率`以及要消除哪些隐藏单元。因为在测试阶段进行预测时，我们不希望输出结果时随机的，如果使用`dropout`函数，预测就会受到干扰。
理论上，只需要多次运行预测处理过程，每一次不同的隐藏单元会被随机归零，预测处理遍历它们，但是计算效率低，得出的结果也几乎相同，与`no dropout`产生的结果极为相似，`inverted dropout`在除以`keep-prob`时可以记住上一步的操作，目的是确保即使在测试阶段不执行`dropout`来调整数值范围，激活函数的预期结果也不会发生变化。所以与训练阶段不同，没必要在测试阶段额外添加`dropout`参数。

### 1.6.2 `Dropout`的原理

一个直观认识是，在`1.6.1`中，使用`dropout`后，经过每次迭代，神经网络似乎变得比之前更小，因此采用一个较小的神经网络好像和使用正则化的效果时一样。

另一个直观认识是，以单个神经元（包含四个输入单元、一个隐藏层单元、一个输入层）为例，利用`dropout`，该单元的输入几乎被消除，但隐藏层单元不能依靠任何特征，因为特征都有可能被随机清除，或者说该单元的输入都有可能被随机清除。所以，不能把所有赌注都放在一个隐藏层节点上，不能给任何一个输入加上太多权重，毕竟它会被删除。因此该单元将通过这种方式积极地传播开来，并为单元的四个输入增加一点权重。通过传播所有权重，`dropout`将产生``压缩权重的平方范数``的效果。

和之前的`L2`正则化类似，实施`dropout`的结果就是**压缩权重**，并完成一些**预防过拟合的外层正则化**。事实证明，`dropout`被正式地作为一种正则化的替代形式，但`L2`对不同权重的衰减是不同的，`L2`取决于倍增的激活函数的大小。总之，`dropout`的功能类似于`L2`正则化，与`L2`正则化不同的是，被应用的方式不同，`dropout`也会有所不同，甚至更适用于不同的输入范围。

### 每一层的`keep-prob`参数可以不同

以下图的神经网络为例：

![image](1.6.2%20dropout原理之三个输入特征网络图.png)

在该神经网络中，其中一个要选择的参数是`keep-prob`，它代表每一层上保留单元的概率，而每一层的`keep-prob`也可以不同。

在第一层上`W`的维度是`(3,7)`，第二层是`(7,7)`，第三层是`(7,3)`，第四层是`(3,2)`，第五层是`(2,1)`。由此可见，`W[2]`是最大的权重矩阵，因为`W[2]`拥有最大的参数集`(7,7)`。为了预防矩阵的过拟合，第二层的权重矩阵`W[2]`的`keep-prob`值应该相对较低，可以设为`0.5`。而其他层的过拟合程度可能没那么严重，它们的`keep-prob`值就会高一些，可以设置为`0.7`或`0.8`。如果不担心某一层的过拟合问题，`keep-prob`值可以设置为`1`（表示保留所有单元，并且不在这一层使用dropout）。

其实，从技术上也可以对输入层使用`dropout`，删除一个或多个输入特征，即使在实际操作过程中通常不这样做，但消除一半的输入特征是不太可能的。这样的话，即使对输入层使用`dropout`，`keep-prob`的值也会接近于1。

### 总结

如果担心某些层比其他层更容易发生过拟合，可以把这些层的`keep-prob`值设置的比其他层低，但缺点是：为了使用交叉验证，需要搜索更多的超参数。

另一种方案是在一些层上使用`dropout`，另一些层上不用，应用`dropout`的层只有一个超参数，即`keep-prob`。

`dropout`的一大缺点就是成本函数`J`不再被明确定义。每次迭代，都会随机移除一些节点。如果再三检查梯度下降的性能，实际上很难进行复查，定义明确的成本函数`J`每次迭代后都会下降。因为所要优化的成本函数`J`实际上并没有被明确定义，或者在某种程度上很难计算，所以失去了调试工具来绘制成本函数下降的函数图像。因为在`dropout`过程中，代码并未引入bug，那么就先可以关闭`dropout`，将`keep-prob`设置为1，运行代码，确保函数`J`单调递减，然后再打开`dropout`函数。

## 1.7 其他正则化方法

除了`L2`正则化和随机失活`dropout`正则化，还有一些方法可以减少神经网络中的过拟合。比如`数据扩增`。

### 1.7.1 数据扩增

#### 1.7.1.1 针对图片分类

假设一个神经网络正在拟合猫的图片分类器，想通过增加训练数据来减少过拟合，但增加训练数据代价太高，或者有时候无法增加数据。

#### 解决办法

通过添加这类图片来增加训练数据，例如水平翻转图片，这样训练数据可以扩大一倍。因为训练集有冗余，虽然这种方法不如额外收集一组新图片那么好，但这样做节约了获取更多猫图片的成本。其实不止可以水平翻转图片，也可以旋转图片、裁切图片。和原图相比，新生成的图片无法得到太多信息，但这样做成本几乎为0。

通过上述方法，就可以增加数据集，额外生成假的训练数据。进而正则化数据集减少过拟合。像这样人工合成数据，就需要通过算法验证图片中的猫经过翻转之后依然是猫。

#### 1.7.1.2 图片中的字符识别

采用旋转或扭曲字形来扩增数据

### 1.7.2 `Early stopping`方法

运行梯度下降时，在训练集上用`0-1`记录分类误差次数，就可以绘制训练误差，或只绘制成本函数`J`的优化过程（呈单调下降趋势）。因为在训练过程中，一直希望训练误差，即代价函数`J`都下降。

通过`early stopping`不但可以绘制训练集成本函数下降图，还可以绘制验证集误差。其中，验证集误差可以是验证集上的分类误差，或者是验证集上的成本函数、逻辑损失和代数损失等。经过对比，随着迭代次数的增多，验证集误差会先呈下降趋势，然后在某一点处开始上升。

`early stopping`的作用是，神经网络在验证集的迭代过程中已经表现很好了，所以在这一点停止训练，得到验证集误差。

#### `early stopping`是怎么发挥作用的呢

当你未在神经网络上运行太多迭代过程的时候，参数`w`接近`0`，因为随机初始化`w`值时，它的值可能都是较小的随机值。在迭代过程和训练过程中，`w`的值会变得越来越大，例如到达验证集误差最小的点。所以`early stopping`要做的就是在中间点停止迭代过程，然后得到一个`w`值中等大小的`佛罗贝尼乌斯范数`。与`L2`正则化类似，在神经网络拟合不严重的基础上，选择参数`w`范数较小的神经网络。

术语`Early stopping`代表提早停止训练神经网络。它的优点是：只运行一次梯度下降，就可以找出`w`的较小值、中间值和较大值，不需要尝试`L2`正则化中`λ`的很多值
但它也有缺点：“优化成本函数”和“减少方差”不能独立进行。因为提早停止梯度下降，也就是停止了优化成本函数，此时就不能再降低成本函数，成本函数的值可能不够小。因为希望不出现过拟合，没有采取不同的方式解决这两个问题，而是用一种方式同时解决两个问题，所以考虑的事情就变得更复杂。

如果不用`early stopping`，另一种方法就是`L2`正则化，训练神经网络的时间就可能很长，这导致超参数的搜索空间更容易分解也更容易搜索。但**缺点**是：必须尝试很多正则化参数`λ`的值，也导致寻找大量`λ`值的计算成本太高。

**总结**：机器学习过程包括几个步骤，其中一步是选择一个算法去优化成本函数`J`，例如梯度下降`Gradient descent`、`Momentum`、`RMSprop`和`Adam`等。但是优化成本函数之后，也有一些方法可以缓解过拟合，比如`正则化`、`扩增数据`等。

在机器学习中，超参数激增，选出可行的算法也变得越来越复杂。如果用一组工具优化成本函数`J`，机器学习就会变得更简单。在重点优化成本函数时，只需要关注`w`和`b`，而`J(w,b)`的值越小越好。

预防过拟合还需要减少方差，这一步需要额外的方法来实现，该方法有时被称为`正交化Orthogonalization`，思路就是在一个时间做一个任务，具体将会在后续章节讲到。

## 1.8 正则化输入

训练神经网络的一个加速方法就是归一化输入。

### 归一化输入的两个步骤

1. 零均值化。令 $\mu =\frac {1}{m}\sum_{i=1}^{m}x^{(i)}$，则实际输入`X`的表达式为 $X=X-\mu$ 。该步骤的意思是移动训练集，直到训练集完成零均值化。
2. 归一化方差。令 $\sigma^{2}=\frac {1}{m}\sum_{i=1}^{m}x^{(i)2}$ ，其中 $x^{(i)2}$ 表示 $x^{(i)}$ 的平方。然后执行$X = X/\sigma^{2}$。

如果用此方法调整训练数据，需要用相同的`μ`和`σ`来归一化测试集。尤其是不希望训练集和测试集的归一化有所不同。而不是在训练集和测试集上分别预估`μ`和`σ`。
***
这里用一个例子进行说明：

| ![image](1.8-1%20正则化输入训练集（拥有两个特征）.png)| ![image](1.8-2%20正则化输入训练集（零均值化后）.png)| ![image](1.8-3%20正则化输入训练集（归一化方差后）.png)|
|----|----|----|
| 图1 原始数据散点图|图2 零均值化后的数据散点图|图3 归一化方差后的数据散点图 |

1. 假设有一个如上图所示的训练集散点图，它有两个输入特征：$x=\begin{bmatrix} x_{1}\\ x_{2} \end{bmatrix}$，它们的数据散点图如图1所示。我们可以看出，图1中的数据分布很不规则，训练时也比较麻烦。
2. 首先执行归一化输入的第一步：`零均值化`。此时`x1`、`x2`的均值都几乎为0，更加方便计算。但是x1的方差比x2的方差大很多，如图2所示。
3. 戒指执行归一化驶入的第二步：`归一化方差`。此时，x1、x2的方差都等于1，分布也比较均匀。如图3所示。

### 归一化输入的原因

回顾成本函数$J(w,b)=\frac {1}{m}\sum_{i=1}^{m}L(\hat y^{(i)},y^{(i)})$

如果使用非归一化的输入特征，成本函数的图像会特别细长狭窄，如果特征值在不同范围，例如$x_{1}\epsilon \left \{ 1,2...1000 \right \}$，$x_{2}\epsilon \left \{ 0...1 \right \}$，结果是参数`w1`、`w2`值的范围或比率将会非常不同，成本函数会像一个非常狭长的碗一样，`w`为横轴、`b`为纵轴的图像会是一个狭长的椭圆。此时学习率必须非常小，梯度下降法也可能需要多次迭代过程，直到最后才能找到最小值。

如果使用归一化的输入特征，成本函数会更对称，`w`为横轴、`b`为纵轴的图像会是一个几乎完美的圆。此时不论从哪个位置开始，梯度下降法都能够更直接地找到最小值，这样就可以在梯度下降法中设置较大步长，即学习率，而不需要像非归一化的输入那样反复执行。

实际上，`w`是一个高维向量，因此使用二维图像绘制`w`并不能对其进行正确表示。但总的理解是成本函数会更圆一点，同时更容易优化（前提为特征都在相似范围内），优化速度也会更快。

## 1.9 梯度消失与梯度爆炸

训练神经网络所面临的一个问题是`梯度消失`或`梯度爆炸`，即训练神经网络时，导数或梯度有时会变得非常大，或非常小，甚至以指数方式变小，这加大了训练的难度。

| ![image](1.9-1%20梯度消失或梯度爆炸之神经网络图.png) |
|----|
假设正在训练一个如上图的极深的神经网络，该神经网络含有参数`w1`、`w2`甚至`w[L]`。当然实际的神经网络比该神经网络更复杂。
同时为了简单起见，使用激活函数`g(z)=z`的线性激活函数，而且令所有层`b=0`。此时最终输出会变为$\hat y$`=w[L]*w[L-1]*w[L-2]...w[2]w[1]*x`，而`z[1]=w[1]*x`，`z[2]=w[2]*w[1]*x`，以此类推。

假设每个权重矩阵`w`为比1大一点的数字，或比单位矩阵大一点，例如`1.5`，由于 $\hat y=w^{L-1}x$，对于一个深度神经网络来说，`L`越大，$\hat y$ 的值也会越大，它是呈指数级增长的。因此对于一个深度神经网络，$\hat y$的值将会**爆炸式增长**。相反，如果权重`w`比1小，例如`0.5`，则会有 $\hat y=w^{L-1}x=0.5^{L-1}x$，因此每个矩阵都小于1，激活函数的值将以**指数级下降**。虽然只是论述了对层数`L`相关函数的激活函数的指数级增长或下降，但这也适用于与层数`L`相关的导数或梯度函数。这会导致训练难度上升，尤其是梯度与`L`相差指数级，梯度下降算法的步长会非常小，梯度下降法将花费更长的时间来学习。

在很长一段时间内，梯度消失与梯度爆炸曾是训练深度神经网络的阻力。虽然有一个解决方案不能彻底解决该问题，但是已经在`选择初始化权重`的问题上提供了很多帮助。具体将在`1.10 神经网络的权重初始化`讲到。

## 1.10 神经网络的权重初始化

针对上节的`梯度消失`或`梯度爆炸`问题，有个解决方案虽然不能彻底解决该问题，但却很有用，有利于为神经网络更谨慎地选择随机初始化参数。为了更好理解，先举一个神经元权重初始化的例子，之后再扩展到整个深度神经网络。

|![image](1.10-1%20单神经元权重初始化.png) |
|----|
上图是一个输入特征为4的单神经元，包含特征`x1`、`x2`、`x3`、`x4`，经过激活函数`a=g(z)`得到 $\hat y$ 。在深度神经网络里，这些特征将会表示为$a^{[L]}$。经过计算，可以得到：$z=w_{1}x_{1}+w_{2}x_{2}+...w_{n}x_{n}=\sum_{i=1}^{n}w_{i}x_{i}$，这里暂时忽略`b`。

计算`z`时，为了预防`z`的值过大或过小，可以发现，当`n`越大，就希望$w_{i}$越小。因此，最合理的方法就是设置变量`w`的方差为：$w_{i}=\frac {1}{n}$，这里的`n`代表输入特征的数量。那么要做的是如下代码：

```text
import numpy as np

W[l] = np.random.randn( shape ) * np.sqrt(1/n[l-1])
# shape为矩阵的shape，n[l-1]为第l层拟合的单元数量，np.sqrt(1/n[l-1])为标准差
```

如果激活函数的输入特征被零均值化和方差标准化后，方差是1，`z`也会调整到相似范围。这虽然没有解决问题，但确实降低了梯度消失和梯度爆炸的问题，因为给权重`W`设置了合理值，所以梯度没有爆炸或消失过快。

另外，还有一些激活函数使用不同的方差，效果会更好，如下所示：

1. 如果使用的是`ReLU`作为激活函数，方差设置为 $w_{i}=\frac {2}{n}$ 效果会更好。
2. 如果使用的是`tanh`作为激活函数，方差设置为 $w_{i}=\frac {1}{n}$ 效果会更好，也被称为`Xavier初始化`。
3. `Yoshua Bengio`和他的同事还提出另外一种方法，方差为 $\frac {2}{n^{[l-1]}+n^{[l]}}$ 。

如果想添加方差为另一个需要调整的超参数，那么调整该超参数的优先级比较低。

## 1.11 梯度检验（确保反向传播的正确）

在实现反向传播`Backprop`时，有一个测试叫`梯度检验`，它的作用是确保`Backprop`正确实现。因为有时虽然写下了一些方程，却不能完全保证执行`Backprop`的所有细节都是正确的。

### 1.11.1 数值逼近`Numerical approximation of gradients`

为了逐步实现梯度检验，这里先讨论如何对计算梯度做数值逼近。以下图为例：

|![image](1.11.1-1%20数值逼近函数图1.png) |
|----|
设该函数方程为 $f(\theta )=\theta^{3}$

假设`θ=1`。不增大`θ`的值，而是在`θ`的右侧设置`θ+ε`，在`θ`左侧设置`θ-ε`，因此`θ=1`，`θ+ε=1.01`，`θ−ε=0.99`。在函数图中画一个三角形，计算高和宽的比值，就是更准确的梯度预估。

|![image](1.11.1-2%20数值逼近函数图2.png) |
|----|
选择`f`函数在`θ−ε`上的这个点，用大三角形的高比上宽，较大三角形的高宽比值更接近于`θ`的导数。把右上角的小三角形下移，好像有了两个三角形，右上角一个，左下角一个。通过这个绿色大三角形同时考虑了这两个小三角形，所以我们得到的不是一个单边公差而是一个双边公差。

计算思路为：`θ+ε`这个点对应的函数值为`f(θ+ε)`，`θ−ε`点对应的函数值为`f(θ−ε)`，大三角形的高度是`f(θ+ε)−f(θ−ε)`，宽度为`2ε`，高宽的比为 $\frac{f(\theta +\epsilon )-f(\theta -\epsilon )}{2\epsilon }$，高宽比的期望值接近于导数`g(θ)`。将`θ=1, θ+ε=1.01, θ−ε=0.99`代入上述高宽比公式，可以算出高宽比的值为`3.0001`，而此时导数`g(θ)=3`，所以这两个`g(θ)`值非常接近，逼近误差为`0.0001`。

如果只考虑单边公差，即从`θ`到`θ+ε`之间的误差，`g(θ)`的值为`3.0301`，逼近误差是`0.03`而不是`0.0001`，所以**使用双边误差的方法更逼近导数的结果**`3`。在梯度检验和反向传播中使用该方法时，运行双边误差与运行两次单边公差的速度一样。

导数的官方定义是针对值很小的`ε`，公式为 $f'(\theta )=\lim_{\epsilon \to 0} \frac{f(\theta +\epsilon )-f(\theta -\epsilon )}{2\epsilon }$ 。对于一个非零的ε，它的逼近误差可以写成$O(\epsilon^{2})$，`ε`的值非常小。如果`ε=0.01`，则$\epsilon^{2}=0.0001$，大写符号`O`的含义是指逼近误差表示为一个常量乘以$\epsilon^{2}$ ，由于它的确很接近误差，所以大写`O`的常量有时是1。

但如果用单边误差公式 $f'(\theta )=\lim_{\epsilon \to 0} \frac{f(\theta +\epsilon )-f(\theta)}{\epsilon }$，逼近误差就是`ε`，当`ε`小于1时，实际上`ε`比$\epsilon^{2}$大很多，所以这个公式的近似值没有上面公式准确。所以在执行梯度检验时，我们使用双边误差，即 $f'(\theta )=\lim_{\epsilon \to 0} \frac{f(\theta +\epsilon )-f(\theta -\epsilon )}{2\epsilon }$，不使用单边公差，因为**单边误差不够准确**。

### 1.11.2 执行梯度检验

逼近梯度的形式找到了，就可以进行梯度检验了。梯度检验可以帮助节省时间以及发现`backprop`实施过程中的bug，即用它调试和检查`backprop`实施是否正确。

假设你的网络中含有参数：$W^{[1]},b^{[1]},W^{[2]},b^{[2]}......W^{[L]},b^{[L]}$。

1. 为了执行梯度检验，首先要做的就是把矩阵`W`和`b`向量化，然后把所有层已经向量过的`W`和`b`连接`concatenate`在一起，成为一个大向量`θ`，则成本函数表示为`J(θ)`。
2. 得到与`W`和`b`顺序相同的数据$dW^{[1]},db^{[1]},dW^{[2]},db^{[2]}......dW^{[L]},db^{[L]}$，用它们来初始化大向量`dθ`，因为它与`θ`有相同维度。与第一步一样，把所有层已经向量过的`dW`和`db`连接`concatenate`在一起，成为一个大向量`dθ`。那么`dθ`与成本函数`J`的梯度有什么关系？

### 梯度检验的步骤`Grad check`

首先我们要清楚，函数`J`是超参数`θ`的一个函数，可以将`J`函数展开为`J(θ1,θ2,...,θn)`，不论超参数向量`θ`的维度是多少。为了实施梯度检验，你要做的就是循环执行，从而对每个`i`也就是对每个`θ`组成元素计算 $d\theta_{approx}^{[i]}$ 的值，这里使用双边误差进行计算，即 $d\theta_{approx}^{[i]}=\frac{J(\theta_1,\theta_2...\theta_i+\epsilon ,...)-J(\theta_1,\theta_2...\theta_i-\epsilon ,...)}{2\epsilon }$。

为了检验`backprop`实施是否正确，我们要将`backprop`的结果 $d\theta^{[i]}=\frac{\partial J}{\partial \theta_i}$ 与双边逼近得到的结果 $d\theta_{approx}^{[i]}$ 相比较。那么该怎么比较`check`呢？

可以使用欧氏距离。因为我们主要是要比较两个向量的对应分量的差别，这个可以用对应分量差的平方和的开方（欧氏距离）来刻画。公式为 $||d\theta_{approx}^{[i]}-d\theta^{[i]}||_2$ ，表示为`误差平方和的平方根`。接着用两个向量长度做归一化，即 $\frac{||d\theta_{approx}^{[i]}-d\theta^{[i]}||_2}{||d\theta_{approx}^{[i]}||_2+||d\theta^{[i]}||_2}$ 。分母只是用于预防这些向量太大或者太小，从而使得这个方程式变成比率，可以得到一个确定的标准去衡量梯度检验的效果。

假设我们的`ε`在这里取 $10^{-7}$ ，那么如果这个比率约为 $10^{-7}$ 或更小，就可以认为这次的梯度检验没有问题；如果这个比率范围为 $10^{-5}$ ，就要稍微考虑一下是哪里出了错，需要把参数向量的每个分量的梯度计算一下，来看一下是哪个分量的梯度计算错误导致了这样的结果；如果这个比率范围为 $10^{-3}$ ，那么结果就更严重了，更加需要把参数向量的每个分量的梯度计算一下来看是哪个计算错误。

在实施神经网络时，经常需要执行`Forprop`和`Backprop`，可能发现这个梯度检验有一个相对较大的值，然后就怀疑存在bug，接着开始调试，直到得到一个很小的梯度检验值。

## 1.12 梯度检验的补充

这里主要介绍在神经网络中实施梯度检验的实用技巧和注意事项。

1. **不要在训练中使用梯度检验，它只用于调试**。计算所有`i`值的 $d\theta_{approx}^{[i]}$ 是一个非常漫长的计算过程，为了实施梯度下降，你必须使用`backprop`来计算 $d\theta^{[i]}$ ，并使用`backprop`来计算导数，只有调试的时候，才会计算它，来确认数值是否接近 $d\theta^{[i]}$ 。完成后，你会关闭梯度检验，梯度检验的每一个迭代过程都不执行它，因为它太慢了。
2. 如果算法的梯度检验失败，要检查所有项，检查每一项，试着找出bug。也就是说，如果 $d\theta_{approx}^{[i]}$ 和 $d\theta^{[i]}$ 的值相差很大，我们要做的就是查找不同的值，看看是哪一步导致 $d\theta_{approx}^{[i]}$ 和 $d\theta^{[i]}$ 的值相差这么多。
3. 在实施梯度检验时，如果使用正则化，请注意正则项，如果代价函数为 $J(\theta )=\frac{1}{m}\sum_{i=1}^{m}L(\hat y^{[i]},y^{[i]})+\frac{\lambda }{2m}\sum_{i=1}^{m}||w^{[l]}||_2^2$ ，而`dθ`等于与`θ`相关的`J`函数的梯度，记住一定要包括正则项。
4. 梯度验证不能与`dropout`同时使用。因为每次迭代过程中，`dropout`会随机消除隐层单元的不同子集，难以计算`dropout`在梯度下降上的成本函数`J`，因此`dropout`可作为优化成本函数`J`的一种方法，但是成本函数`J`被定义为对所有指数极大的节点子集求和，而在任何迭代过程中，这些节点都有可能被消除，所以很难计算代价函数`J`。这里只是对成本函数做抽样，用`dropout`每次随机消除不同的子集，所以很难用梯度检验来双重检验`dropout`的计算，所以一般**不同时使用**`梯度检验`和`dropout`。但如果你想这样做，可以把`dropout`中的`keep-prob`设置为`1`，然后打开`dropout`并寄希望于`dropout`的实施是正确的。

   除此之外，还可以做点别的事情，比如修改节点丢失的模式，确认梯度检验是正确的。建议关闭`dropout`用梯度检验进行双重检查，在没有`dropout`的情况下，你的算法至少是正确的，然后打开`dropout`。

5. 这也是比较微妙的一点，现实中几乎不会出现这种去情况，当`w`和`b`接近`0`时，在随机初始化时梯度下降的实施是正确的。但是在运行梯度下降时，`w`和`b`变得更大，可能只有在`w`和`b`接近`0`时，`backprop`的实施才是正确的。但是当`w`和`b`变大时，它会变得越来越不准确。

需要做一件事，就是在随机初始化过程中，运行`梯度检验`，然后再训练网络，`w`和`b`会有一段时间远离`0`，如果随机初始化值比较大，反复训练网络之后，再重新运行梯度检验。
