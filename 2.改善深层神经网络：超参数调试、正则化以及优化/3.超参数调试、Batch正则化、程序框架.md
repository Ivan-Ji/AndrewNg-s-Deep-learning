<!-- TOC -->

- [3. 超参数调试、Batch正则化、程序框架](#3-超参数调试batch正则化程序框架)
    - [3.1 调试处理（调参）Tuning Process](#31-调试处理调参tuning-process)
    - [3.2 超参数的合适范围](#32-超参数的合适范围)
        - [但`随机取值`和`均匀取值`对于某些超参数是不适用的，如下所示](#但随机取值和均匀取值对于某些超参数是不适用的如下所示)
    - [3.3 超参数训练的实践](#33-超参数训练的实践)
        - [1. Babysitting one model（只训练一个模型）](#1-babysitting-one-model只训练一个模型)
        - [2. train many models（同时训练多个模型）](#2-train-many-models同时训练多个模型)
    - [3.4 归一化网络的激活函数（重要！！！）Batch Norm（BN）](#34-归一化网络的激活函数重要batch-normbn)
        - [3.4.1 Batch归一化如何发挥作用](#341-batch归一化如何发挥作用)
        - [3.4.2 Batch 归一化的使用方法](#342-batch-归一化的使用方法)
            - [3.4.2.1 归一化隐藏单元值](#3421-归一化隐藏单元值)
            - [$γ$ 和 $β$ 的作用](#γ-和-β-的作用)
            - [小提示](#小提示)
    - [3.5 神经网络中的 Batch_Norm（将 Batch_Norm 拟合进神经网络）](#35-神经网络中的-batch_norm将-batch_norm-拟合进神经网络)
        - [3.5.1 Batch Norm 在深度网络训练中拟合的步骤](#351-batch-norm-在深度网络训练中拟合的步骤)
            - [深度学习框架里的 Batch 归一化](#深度学习框架里的-batch-归一化)
        - [3.5.2 Batch 归一化与 mini-batch 的结合](#352-batch-归一化与-mini-batch-的结合)
        - [总结](#总结)
    - [3.6 Batch Norm 奏效的原因](#36-batch-norm-奏效的原因)
        - [**Covariate shift** 的问题如何应用于神经网络](#covariate-shift-的问题如何应用于神经网络)
        - [Batch归一化如何解决**Covariate shift** 的问题](#batch归一化如何解决covariate-shift-的问题)
    - [3.7 测试时的Batch Norm](#37-测试时的batch-norm)
    - [3.8 Softmax 回归](#38-softmax-回归)
        - [3.8.1 Softmax 回归的主要思想](#381-softmax-回归的主要思想)
        - [3.8.2 Softmax 与 hardmax 的对比](#382-softmax-与-hardmax-的对比)
        - [3.8.3 Softmax 分类的损失函数](#383-softmax-分类的损失函数)
        - [3.8.4 向量化的 Softmax 表示](#384-向量化的-softmax-表示)
        - [3.8.5 在有Softmax输出层时如何实现梯度下降法](#385-在有softmax输出层时如何实现梯度下降法)
    - [3.9 深度学习框架与 Tensorflow](#39-深度学习框架与-tensorflow)
        - [3.9.1 深度学习框架](#391-深度学习框架)
        - [3.9.2 Tensorflow](#392-tensorflow)
            - [3.9.2.1 tensorflow 的初步用法](#3921-tensorflow-的初步用法)
            - [3.9.2.2 在tensorflow训练时添加训练数据](#3922-在tensorflow训练时添加训练数据)
            - [3.9.2.3 计算图的写法](#3923-计算图的写法)
            - [3.9.2.4 TensorFlow程序的核心](#3924-tensorflow程序的核心)

<!-- /TOC -->

# 3. 超参数调试、Batch正则化、程序框架

## 3.1 调试处理（调参）Tuning Process

如果想尝试调整一些超参数，该如何选择调试值呢？

在早一代的机器学习算法中，如果有两个超参数，常见的做法是在网格中取样点，然后系统的研究这些数值，例如放置 $5*5$ 的点。

| ![image](3.1-1%20调试处理之25点网格图.png) |
|----|

当参数的数量相对较少时，对于这个例子，可以尝试所有的25个点，然后选择哪个参数效果最好。这个方法很实用。

在深度学习领域，推荐使用下面的做法。随机选择点，可以选择同等数量的25个点，接着用这些随机取的点试验超参数的效果，之所以这么做是因为对于你要解决的问题而言，很难提前知道那个超参数最重要。取一个极端例子，假设超参数一是学习率 $\alpha$，假设超参数二是 $Adam$ 算法中分母中 $ε$ ，这种情况下 $\alpha$ 的取值很重要，而 $ε$ 的取值则无关紧要。

如果在网格中取点，接着试验了 $\alpha$ 的5个取值，那么会发现无论 $ε$ 取何值，结果基本上都是一样的。一共有25种模型，但是进行试验的 $\alpha$ 值只有5个。如果随机取值，可以试验25个独立的 $\alpha$ 的值，这样似乎可以发现效果最好的那个。

| ![image](3.1-2%20调试处理之随机网格图.png) |
|----|

如果有三个超参数，要搜索的不是一个方格，而是一个立方体，接着在三维立方体中取值，你会试验大量的更多的值。在实践中，要搜索的可能不止三个超参数，有时很难预知哪个是最重要的超参数。对于具体应用而言，随机取值而不是网格取值表明，探究了更多重要超参数的潜在值。

无论结果是什么，当你给超参数取值时，另一个惯例是采用**从粗糙到精细**的策略。比如在二维的例子中进行取值，也许会发现效果最好的某个点，也许这个点周围的其它一些点效果也很好。那么接下来要做的是放大这块小区域，然后在其中更密集地取值或随机取值，聚集更多的资源在这个小区域中搜索。如果你怀疑这些超参数在这个区域的最优结果，拿在整个的方格中进行粗略搜索后，接下来聚焦在更小的方格中。在更小的方格中，可以更密集地取点。所以这种从粗到细的搜索也经常使用。

通过实验超参数的不同取值，可以选择对于训练集目标而言的最优值或对于开发集而言的最优值，或者在超参搜索过程中你最想优化的东西。

## 3.2 超参数的合适范围

上一节已经看到，在超参数范围内，随机取值可以提升搜索效率，但随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺用于探究超参数。

1. 要选取隐藏单元的数量 $n^{[l]}$ ，对于给定层，假设选择的取值范围是从50到100中的某点，这种情况下，对于50-100的数轴，可以**随机**在其上取点，这是一个搜索特定超参数的很直观的方式。

2. 如果要选取神经网络的层数，称之为字母 $L$ ，也许会选择层数为2到4中的某个值，接着顺着2,3,4随机均匀取样才比较合理，还可以应用网格搜索。这是集合随机均匀取值的例子。

### 但`随机取值`和`均匀取值`对于某些超参数是不适用的，如下所示

1. 假设在搜索超参数--学习率 $\alpha$ ，假设其值最小是0.0001，或者最大值是1，如果画一条从0.0001到1的数轴，沿其随机均匀取值，那么90%的数值将会落在0.1到1之间，结果就是在0.1到1之间应用了90%的资源，而在0.0001到0.1之间只有10%的搜索资源，这看上去不太对，反而用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取0.0001，0.001，0.01，1，在对数轴上均匀随机取点，这样在0.0001到0.001之间就会有更多的搜索资源可，还有在0.001到0.01之间等等。分别取对数可以得到0.0001-1之间的对数范围是-4-0，然后可以设置 $\alpha$ 的值，基于随机取样的超参数值 $\alpha=10^r$ 。

    ```text
    r = -4 * np.random.rand()    # r ∈ [-4,0]
    α = 10 ^ r
    ```

    因此，学习率在对数坐标上取值，取最小值的对数得到 a 值，取最大值的对数得到 b 值，所以现在在对数轴上的 $10^a$ 到 $10^b$ 区间取值，在 a 和 b 之间随机均匀的选取r值，将超参数设置为 $10^r$ ，这就是在对数轴上取值的过程。

2. 另一个棘手的例子是给 $\beta$ 取值，用于计算指数加权平均值。假设 $\beta$ 是某个从 $0.9$ 到 $0.999$ 之间的值。当计算指数加权平均值时，取0.9就像在10个值中计算平均值，有点类似于计算10天的温度平均值，而取0.999就是在1000个值中取平均。如果想在 $0.9$ 到 $0.999$区间搜索，就不能用线性轴取值，所以考虑这个问题最好的方法就是探究 $1-\beta$ ，此值在 $0.1$ 到 $0.001$ 区间内，所以我们会给 $1-\beta$ 取值，采用对数轴，$0.1$ 的对数取值为 $-1$ ， $0.001$ 的对数取值为 $-1$。这里设定了 $1-\beta=10^r$ ，所以 $\beta=1-10^r$ 就变成了超参数随机取值。

## 3.3 超参数训练的实践

如今的深度学习已经应用到许多不同的领域，某个应用领域的超参数设定，有可能通用于另一领域，不同的应用领域出现相互交融。比如，曾经看到过计算机视觉领域中涌现的巧妙方法，比如说Confonets或ResNets，这我们会在后续课程中讲到。它还成功应用于语音识别，我还看到过最初起源于语音识别的想法成功应用于NLP等等。

深度学习领域中，发展很好的一点是，不同应用领域的人们会阅读越来越多其它研究领域的文章，跨领域去寻找灵感。

就超参数的设定而言，见到过有些直觉想法变得很缺乏新意，所以，即使你只研究一个问题，比如说逻辑学，你也许已经找到一组很好的参数设置，并继续发展算法，或许在几个月的过程中，观察到你的数据会逐渐改变，或也许只是在你的数据中心更新了服务器，正因为有了这些变化，你原来的超参数的设定不再好用，

所以建议，重新测试或评估你的超参数，至少每隔几个月一次，以确保你对数值依然很满意。最后，关于如何搜索超参数的问题，见过大概两种重要的思想流派或人们通常采用的两种重要但不同的方式。如下所示：

| ![image](3.3-1%20超参数训练的实践之搜索超参数思想图.png) |
|----|

### 1. Babysitting one model（只训练一个模型）

第一种是你照看一个模型，通常是有庞大的数据组，但没有许多计算资源或足够的CPU和GPU的前提下，基本而言，你只可以一次负担起试验一个模型或一小批模型，在这种情况下，即使当它在试验时，你也可以逐渐改良。

比如，第0天，你将随机参数初始化，然后开始试验，然后你逐渐观察自己的学习曲线，也许是损失函数J，或者数据设置误差或其它的东西，在第1天内逐渐减少，那这一天末的时候，你可能会说，看，它学习得真不错。

我试着增加一点学习速率，看看它会怎样，也许结果证明它做得更好，那是你第二天的表现。两天后，你会说，它依旧做得不错，也许我现在可以填充下Momentum或减少变量。

然后进入第三天，每天，你都会观察它，不断调整你的参数。也许有一天，你会发现你的学习率太大了，所以你可能又回归之前的模型，像这样，但你可以说是在每天花时间照看此模型，即使是它在许多天或许多星期的试验过程中。所以这是一个人们照料一个模型的方法，观察它的表现，耐心地调试学习率，但那通常是因为你没有足够的计算能力，不能在同一时间试验大量模型时才采取的办法。

### 2. train many models（同时训练多个模型）

另一种方法则是同时试验多种模型，你设置了一些超参数，尽管让它自己运行，或者是一天甚至多天，然后你会获得像类似上面的学习曲线，这可以是损失函数J或实验误差或损失或数据误差的损失，但都是你曲线轨迹的度量。

同时你可以开始一个有着不同超参数设定的不同模型，所以，你的第二个模型会生成一个不同的学习曲线，也许是像这样的一条（紫色曲线），我会说这条看起来更好些。与此同时，你可以试验第三种模型，其可能产生一条像这样的学习曲线（红色曲线），还有另一条（绿色曲线），也许这条有所偏离，像这样，等等。或者你可以同时平行试验许多不同的模型，橙色的线就是不同的模型。用这种方式你可以试验许多不同的参数设定，然后只是最后快速选择工作效果最好的那个。在这个例子中，也许这条看起来是最好的（绿色曲线）。

打个比方，我把左边的方法称为熊猫方式。当熊猫有了孩子，他们的孩子非常少，一次通常只有一个，然后他们花费很多精力抚养熊猫宝宝以确保其能成活，所以，这的确是一种照料，一种模型类似于一只熊猫宝宝。

对比而言，右边的方式更像鱼类的行为，我称之为鱼子酱方式。在交配季节，有些鱼类会产下一亿颗卵，但鱼类繁殖的方式是，它们会产生很多卵，但不对其中任何一个多加照料，只是希望其中一个，或其中一群，能够表现出色。

这就是哺乳动物繁衍和鱼类，很多爬虫类动物繁衍的区别。我将称之为熊猫方式与鱼子酱方式，因为这很有趣，更容易记住。

所以这两种方式的选择，是由你拥有的计算资源决定的，如果你拥有足够的计算机去平行试验许多模型，那绝对采用鱼子酱方式，尝试许多不同的超参数，看效果怎么样。

但在一些应用领域，比如在线广告设置和计算机视觉应用领域，那里的数据太多了，你需要试验大量的模型，所以同时试验大量的模型是很困难的，它的确是依赖于应用的过程。但我看到那些应用熊猫方式多一些的组织，那里，你会像对婴儿一样照看一个模型，调试参数，试着让它工作运转。尽管，当然，甚至是在熊猫方式中，试验一个模型，观察它工作与否，也许第二或第三个星期后，也许应该建立一个不同的模型（绿色曲线），像熊猫那样照料它，这样一生中可以培育几个孩子，即使它们一次只有一个孩子或孩子的数量很少。

所以希望你能学会如何进行超参数的搜索过程，现在，还有另一种技巧，能使你的神经网络变得更加坚实，它并不是对所有的神经网络都适用，但当适用时，它可以使超参数搜索变得容易许多并加速试验过程，我们在下个笔记中再讲解这个技巧。

## 3.4 归一化网络的激活函数（重要！！！）Batch Norm（BN）

在深度学习兴起后，最重要的一个思想是它的一种算法，叫做Batch归一化。Batch归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会使你的训练更加容易，甚至是深层网络。

### 3.4.1 Batch归一化如何发挥作用

当训练一个模型，比如logistic回归时，你也许会记得，归一化输入特征可以加快学习过程。你计算了平均值 $μ$，从训练集中减去平均值 $X-μ$ ，计算了方差 $σ^2$ ，接着根据方差归一化数据集 $\frac{X-μ}{σ^2}$ ，在之前的笔记中我们看到，这是如何把学习问题的轮廓，从很长的东西，变成更圆的东西，更易于算法优化（使均值为0、方差为1）。所以这对logistic回归和神经网络的归一化输入特征而言是有效的。

**那么更深的模型呢？**

| ![image](3.4-1%20归一化网络的激活函数之Logistic回归网络.png) |
|----|

在训练神经网络的时候，不仅输入了特征值x，而且第一层有激活值 $a^{[2]}$ ，第二层有激活值 $a^{[2]}$ 等等。

如果你想训练参数，比如 $w^{[3]},b^{[3]}$ ，那一般的想法是归一化 $a^{[2]}$ 的平均值和方差，以便使 $w^{[3]},b^{[3]}$ 的训练更有效率。

所以问题是，对任何一个隐藏层而言，能否归一化 $a$ 值呢？在此例中，比如说 $a^{[2]}$ 的值，但可以是任何隐藏层的，以更快的速度训练 $w^{[3]},b^{[3]}$ ，因为 $a^{[2]}$ 是下一层的输入值，所以会影响 $w^{[3]},b^{[3]}$ 的训练。

实践中，经常做的是归一化 $z^{[2]}$ (意思就是在上一层网络输出时进行归一化，而不是在激活函数激活之后再进行归一化)，所以这就是我介绍的版本，我推荐其为默认选择，那下面就是

### 3.4.2 Batch 归一化的使用方法

#### 3.4.2.1 归一化隐藏单元值

在神经网络中，假设第 $l$ 层有隐藏单元值，即 $z^{(i)}$，从 $z^{(1)}$ 到 $z^{(m)}$ 。则归一化的公式如下：

1. $\mu=\frac{1}{m}\sum_{i}z^{(i)}$

2. $\sigma^2=\frac{1}{m}\sum_{i}(z_i-\mu)^2$

3. $z^{(i)}_{norm}=\frac{z^{(i)-\mu}}{\sqrt{\sigma^2+\epsilon}}$ ， 这里为了使数值稳定，通常将ε作为分母，以防 $σ=0$ 的情况。

现在已经把这些z值标准化，使之平均值为0，并且标准化单位方差，所以z的每一个分量都含有平均值0和方差1，但我们不想让隐藏单元总是含有平均值0和方差1，也许隐藏单元有了不同的分布会有意义，所以我们所要做的就是计算如下式子：

* $\tilde{z}^{(i)}=\gamma z^{(i)}_{norm}+\beta$

此时γ和β就是模型的学习参数。所以我们使用梯度下降或一些其它类似梯度下降的算法，比如Momentum或者Nesterov，Adam，就可以更新 $γ$ 和 $β$ ，正如更新神经网络的权重一样。

#### $γ$ 和 $β$ 的作用

可以随意设 $\tilde{z}^{(i)}$ 的平均值，事实上，如果 $γ=\sqrt{σ^2+ε},β=μ$ ，那么 $\tilde{z}^{(i)}=\gamma z^{(i)}_{norm}+\beta$ 的作用在于，它会精确转化`3.4.2.1 归一化隐藏单元值`的第三个方程。那么如果如果 $γ=\sqrt{σ^2+ε},β=μ$ 成立，则 $\tilde{z}^{(i)}=z^{(i)}$。

通过对 $γ$ 和 $β$ 合理设定，归一化过程，即这四个等式，从根本来说，只是计算恒等函数。通过赋予 $γ$ 和 $β$ 其它值，可以使你构造含其它平均值和方差的隐藏单元值。现在用 $\tilde{z}^{(i)}$ 取代 $z^{(i)}$ ，方便神经网络中的后续计算。

Batch归一化的作用是它适用的归一化过程，不只是输入层，甚至同样适用于神经网络中的深度隐藏层。

#### 小提示

* 应用Batch归一化了一些隐藏单元值中的平均值和方差，不过训练输入和这些隐藏单元值的一个区别是，你也许不想隐藏单元值必须是平均值0和方差1。

* 比如，如果你有 `sigmoid` 激活函数，不想让你的值总是全部集中在`sigmoid`图像的中间部分，希望它们有更大的方差，或不是0的平均值，以便更好的利用非线性的sigmoid函数，而不是使所有的值都集中于线性区间中，

* 这就是为什么有了 $γ$ 和 $β$ 两个参数后，你可以确保所有的 $z^{(i)}$ 值可以是你想赋予的任意值，或者它的作用是保证隐藏的单元已使均值和方差标准化。

* 均值和方差由 $γ,β$ 两参数控制，即，学习算法可以设置为任何值，所以它真正的作用是，使隐藏单元值的均值和方差标准化，即 $z^{(i)}$ 有固定的均值和方差，均值和方差可以是0和1，也可以是其它值。

## 3.5 神经网络中的 Batch_Norm（将 Batch_Norm 拟合进神经网络）

上一节的等式可以在单一隐藏层进行Batch归一化，接下来，让我们看看它是怎样在深度网络训练中拟合的吧。

|![image](3.5-1%20Batch_Norm%20拟合进神经网络之神经网络图.png) |
|----|

### 3.5.1 Batch Norm 在深度网络训练中拟合的步骤

先计算 $z$ ，然后应用其到激活函数中计算 $a$ ，每个圆圈代表着两步的计算过程。同样的，对于下一层而言，那就是 $z^{[2]}$和 $a^{[2]}$ 等。

1. 如果没有应用Batch归一化，一般把输入 $X$ 拟合到第一隐藏层，然后首先计算 $z^{[1]}$ ，这是由 $w^{[1]},b^{[1]}$ 两个参数控制的。再把 $z^{[1]}$ 拟合到激活函数计算 $a^{[1]}$ 。

2. Batch归一化的做法是将 $z^{[1]}$ 值进行 Batch 归一化，简称 **BN** 。第一层的过程将由 $β^{[1]},γ^{[1]}$两参数控制，这一操作会给你一个新的规范化的 $z^{[1]}$ 值，即 $\tilde{z}^{[1])}$ 。然后将其输入激活函数中得到 $a^{[1]}$ ，即 $a^{[1]}=g^{[1]}(\tilde{z}^{[l]})$。

3. 与第一层类似，在第二层中，将 $z^{[2]}$ 进行 Batch 归一化，即 $β^{[2]},γ^{[2]}$ ，可以得到 $\tilde{z}^{[2]}$，再通过激活函数计算出 $a^{[2]}$ 等等。

**注意**：此时是将一些参数，如 $β^{[1]},β^{[2]},γ^{[1]},γ^{[2]}$ 等参数加入到此新网络中。但这里的 $β^{[1]},β^{[2]}$ 和超参数 $β$ 没有任何关系，超参数 $β$ 是用于 Momentum 或计算各个指数加权平均值。所以这是算法的新参数，接下来你可以使用想用的任何一种优化算法，比如使用梯度下降法来执行它。

例如，对于给定层，需要计算 $dβ^{[l]}$ ，接着更新参数 $β$ 为 $β^{[l]}=β^{[l]}-αdβ^{[l]}$ ，也可以使用Adam或RMSprop或Momentum，以更新参数β和γ，并不是只应用梯度下降法。

#### 深度学习框架里的 Batch 归一化

如果**Batch归一化**使用的是深度学习框架，通常不必自己把Batch归一化步骤应用于Batch归一化层。因此，在框架中**Batch归一化**可写成一行代码，比如说，在 TensorFlow 中，可以使用函数`tf.nn.batch_normalization`来实现。但实践中，不必操作所有这些具体的细节，但知道它是如何作用的，因为可以更好的理解代码的作用。

### 3.5.2 Batch 归一化与 mini-batch 的结合

实践中，Batch归一化通常和训练集的mini-batch一起使用。方式如下：

1. 第一个mini-batch 使用参数 $w^{[1]}$ 和 $b^{[1]}$ 计算 $z^{[1]}$ 。接着Batch归一化会减去均值，除以标准差，由 $β^{[1]}$ 和 $γ^{[1]}$ 重新缩放，这样就得到 $\tilde{z}^{[1]}$ ，你再应用激活函数得到 $a^{[1]}$ 。然后用 $w^{[2]}$ 和 $b^{[2]}$ 计算 $z^{[2]}$ 等，这一切都是基于第一个mini-batch上进行的一步梯度下降法。

2. 类似的，在第二个mini-batch上计算 $z^{[1]}$，再用第二个mini-batch中的数据实现归一化，即计算出 $\tilde{z}^{[1]}$ 。后面的层也是如此。

3. 在第三个mini-batch（$X^{\left\{3\right\}}$ ）上同样这样做，继续训练。

这里有参数 $b^{[l]}$ 的细节，如下：

* 先前每层的参数是 $w^{[l]},b^{[l]},β^{[l]},γ^{[l]}$ ，而 $z^{[l]}=w^{[l]} a^{[l-1]} +b^{[l]}$ 。 将 $z^{[l]}$ 归一化的过程中，无论 $b^{[l]}$ 的值是多少，都是要被减去的，因为在Batch归一化的过程中，你要计算z^([l])的均值，再减去平均值。所以，使用Batch归一化可以消除 $b^{[l]}$ 这个参数；或者也可以，暂时把它设置为0。那么，计算公式变成了 $z^{[l]}=w^{[l]} a^{[l-1]}$ ，然后计算归一化的 $\tilde{z}^{[l]}=γ^{[l]} z^{[l]}+β^{[l]}$。

* 因为Batch归一化使 $z^{[l]}$ 的均值为零，b^([l])这个参数没有意义，所以，你必须去掉它，由控制参数 $β^{[l]}$ 代替，它会影响转移或偏置条件。

最后，要记住 $z^{[l]}$ 的维数，在这个例子中，如果 $n^{[l]}$是 $l$ 层隐藏单元的数量，那么 $z^{[l]},b^{[l]}\beta^{[l]},\gamma^{[l]}$ 的维度都是 $(n^{[l]},1)$因为这是你隐藏层的数量，你有 $n^{[l]}$ 个隐藏单元，所以 $\beta^{[l]},\gamma^{[l]}$用来将每个隐藏层的均值和方差缩放为神经网络想要的值。

### 总结

假设你在使用mini-batch梯度下降法

```text
for t=1 to mini-batch-num:
    前向传播：在 X{t} 上计算
        在每个隐藏层上使用 batch 归一化（BN），确保 z 值有归一化的均值和方差
    反向传播：计算dw[l], db[l], dβ[l], dγ[l]（这里可以去掉db[l]）
    更新参数：
        w[l]=w[l]-αdw[l],
        β[l]=β[l]-αdβ[l],
        γ[l]=γ[l]-αdγ[l]            更新参数可以用梯度下降法、Momentum、RMSprop、Adam
```

## 3.6 Batch Norm 奏效的原因

为什么Batch归一化会起作用呢？

第一个原因是，归一化输入特征值x，使其均值为0，方差1。有一些从0到1而不是从1到1000的特征值，通过归一化所有的输入特征值x，以获得类似范围的值，可以**加速学习**。Batch归一化起的作用的原因，直观的一点就是，它在做类似的工作，但不仅仅对于输入值，还有隐藏单元值，这只是Batch归一化作用的冰山一角，

第二个原因是，它可以使权重比神经网络更滞后或更深层，比如，相比于神经网络中前面几层的权重，比如第1层，第10层的权重更能经受得住变化，以下图为例：

| ![image](3.6-1%20Batch_Norm奏效的原因之猫的判别图.png) |
|----|

这是一个建立在猫脸识别上的神经网络的训练。假设已经在所有黑猫的图像上训练了数据集，如果现在你要把此网络应用于有色猫，这种情况下，正面的例子不只是左边的黑猫，还有右边其它颜色的猫，那么神经网络的分类效果可能不会很好。

**改变数据分布**，这里称之为 **Covariate shift**，它的思路为：假设神经网络已经学习了 $x->y$ 的映射，如果 $x$ 的分布改变了，那么就可能需要重新训练神经网络算法。这种做法同样适用于该情况：如果真实函数 $x->y$ 的映射保持不变，训练你的函数的需要变得更加迫切，如果真实函数也改变，情况会更差

### **Covariate shift** 的问题如何应用于神经网络

| ![image](3.6-2%20Batch_Norm奏效的原因之深层神经网络图1.png) |
|----|

一个像上图的深度网络，从隐藏层第三层来看学习过程：该网络已经学习了参数 $w^{[3]}$ 和 $b^{[3]}$ ，接着它需要做什么，才能使输出值 $\hat{y}$ 接近真实值 $y$ 呢？

| ![image](3.6-3%20Batch_Norm奏效的原因之深层神经网络图2.png) |
|----|

从隐藏层第三层来看，它从上一层得到一些值，例如$a_1^{[2]}, a_2^{[2]}, a_3^{[2]}, a_4^{[2]}$ ，当然这些值也可以是特征值 $x_1，x_2，x_3，x_4$ 。因此第三层隐藏层的工作是找到一种方式，使这些值映射到 $\hat{y}$ 。这样从第三层往后可以做一些截断，所以这些参数 $w^{[3]}, b^{[3]}, w^{[4]}, b^{[4]}, w^{[5]}, b^{[5]}$，也就是学习这些参数。

|![image](3.6-4%20Batch_Norm奏效的原因之深层神经网络图3.png) |
|----|

第三层网络的左边还有参数 $w^{[1]}, b^{[1]}, w^{[2]}, b^{[2]}$，如果这些参数改变，a^([2])的值也会改变。所以从第三层隐藏层的角度来看，这些隐藏单元的值在不断地改变，所以它就有了“Covariate shift”的问题。

### Batch归一化如何解决**Covariate shift** 的问题

1. **Batch归一化**减少了这些隐藏值分布变化的数量。

   当神经网络在之前层中更新参数，Batch归一化可以确保无论其怎样变化， $z_1^{[2]}, z_2^{[2]}$的均值和方差保持不变，即使 $z_1^{[2]}, z_2^{[2]}$的值改变，至少他们的均值和方差也会是均值0，方差1（或者不一定均值0，方差1，但由 $β^{[2]}, γ^{[2]}$ 决定的值）。它做的是，它限制了在前层的参数更新，会影响数值分布的程度，第三层看到的这种情况，因此得到学习。

    Batch归一化减少了输入值改变的问题，当改变输入值时，后层适应的程度减小了，减弱了前层参数的作用与后层参数的作用之间的联系，它使得网络每层都可以自己学习，稍稍独立于其它层，这有助于加速整个网络的学习。因为它们被同样的均值和方差所限制，所以会使得后层的学习工作变得更容易些。

2. Batch归一化还有一个轻微的正则化效果。

   Batch归一化中非直观的一件事是，每个mini-batch的值为均值和方差缩放的 $z^{[t]}, z^{[l]}$。因为不是在整个数据集上而在mini-batch上计算，均值和方差有一些小的噪声，毕竟它只是由一小部分数据估计得出的。同样缩放过程从 $z^{[l]}$ 到 $\tilde{z}^{[l]}$，过程也有一些噪音。

   这里的均值和标准差的估计值也是有噪音的，所以类似于dropout，Batch归一化有轻微的正则化效果，这迫使后面的单元不过分依赖任何一个隐藏单元，类似于dropout（dropout给隐藏层增加了噪音），因此有轻微的正则化效果。因为添加的噪音很微小，所以并不是巨大的正则化效果。所以如果你想得到dropout更强大的正则化效果，可以将Batch归一化和dropout一起使用。

   例如：如果你应用了较大的mini-batch，比如说，你用了512而不是64，通过应用较大的min-batch，你减少了噪音，因此减少了正则化效果，这是dropout的一个奇怪的性质，就是应用较大的mini-batch可以减少正则化效果。

因此有时候可以把Batch归一化当成一种正则化，有时它会对你的算法有额外的期望效应或非期望效应。但是不要完全把Batch归一化当作正则化，而是把它当作归一化隐藏单元激活值并加速学习的方式。

## 3.7 测试时的Batch Norm

Batch归一化将你的数据以mini-batch的形式逐一处理，但在测试时，可能需要对每个样本逐一处理，所以来看一下怎样调整神经网络来做到这一点：

1. $\mu=\frac{1}{m}\sum_{i}z^{(i)}$

2. $\sigma^2=\frac{1}{m}\sum_{i}(z_i-\mu)^2$

3. $z^{(i)}_{norm}=\frac{z^{(i)-\mu}}{\sqrt{\sigma^2+\epsilon}}$

4. $\tilde{z}^{(i)}=\gamma z^{(i)}_{norm}+\beta$

上述公式是在训练时用来执行Batch归一化的等式。在一个mini-batch中，用 $m$ 来表示这个mini-batch中的样本数量，而不是整个训练集。需要注意的是，用于调节计算的 $μ, σ^2$ 是在整个mini-batch上进行计算，但是在测试时，不可能将一个mini-batch中的64，128或256个样本同时处理，因此你需要用其它方式来得到 $μ, σ^2$ ，而且如果只有一个样本，一个样本的均值和方差没有意义。

所以实际上，为了将你的神经网络运用于测试，就需要单独估算 $μ, σ^2$ ，在典型的Batch归一化运用中，需要用一个**指数加权平均**来估算（这个平均数涵盖了所有mini-batch）。

我们选择 $l$ 层，假设我们有mini-batch（$X^{\left\{1\right\}}, X^{\left\{2\right\}}, X^{\left\{3\right\}}……$ ）以及对应的 $y$ 值等。那么在为 $l$ 层训练第一个mini-batch（$X^{\left\{1\right\}}$）时，就得到了均值 $\mu^{\left\{1\right\}[l]}$；训练第二个mini-batch，会得到均值 $\mu^{\left\{2\right\}[l]}$；第三个mini-batch会得到均值 $\mu^{\left\{3\right\}[l]}$。

类似之前用**指数加权平均**来计算 $θ_1, θ_2, θ_3$ 的均值，指数加权平均就成了对这一隐藏层的 $z$ 均值的估值 $\mu$。同样的，可以用指数加权平均来追踪你在这一层的第一个mini-batch中所见的 $σ^2$ 的值，以及第二个mini-batch中所见的 $σ^2$ 的值等等。因此在用不同的mini-batch训练神经网络的同时，能够得到所查看的每一层的 $μ,σ^2$ 的指数加权平均的实时数值。

最后在测试时，对应等式 $z^{(i)}_{norm}=\frac{z^{(i)-\mu}}{\sqrt{\sigma^2+\epsilon}}$ ，只需要用测试时正向传播的 $z$ 值来计算 $z_{norm}^{(i)}$（这里用 $μ,σ^2$ 的指数加权平均），然后可以用刚算出来的 $z_{norm}$ 和神经网络训练过程中得到的参数 $β,γ$ 来计算测试样本的 $\tilde{z}$。

**总结** ：在训练时， $μ,σ^2$ 是在整个mini-batch上计算出来的，包含了一定数量的样本。但在测试时，需要逐一处理样本，方法是根据训练集估算的 $μ,σ^2$ ，理论上可以在最终的网络中运行整个训练集来得到，但在实际操作中，我们通常运用指数加权平均来追踪训练过程中的 $μ,σ^2$ 。然后在测试中使用 $μ,σ^2$ 的值来进行所需隐藏单元值 $z$ 的调整。该过程比较稳健。如果使用深度学习框架，通常会有默认的估算 $μ,σ^2$ 的方式，一样会起到比较好的效果。

任何合理的估算隐藏单元值均值和方差的方式，在测试中都会有效。

## 3.8 Softmax 回归

之前的逻辑回归一般应用于**二分类问题**。但碰到多分类问题时，就需要使用**Softmax 回归**了。

之前有猫的判别问题。假设现在有很多图片，里面有`猫、狗、小鸡`。这里把猫当作做`类别1`，狗为`类别2`，小鸡是`类别3`，如果不属于以上任何一类，就分到`其它`，即`类别4`。

这里用大写的C来表示输入数据会被分入的类别总个数（$C=4$）。当有4个分类时，就会用索引表示，即从0到C-1，换句话说就是0、1、2、3。所以，可以建立一个输出层数据为4的神经网络。在该网络中，我们希望输出层单元的数字告诉我们这4种类型中每个的概率有多大，所以这里的每个节点输出的数字应该是概率，而输出中的四个数字加起来应该等于1。所以这里就要用到Softmax层，以及输出层来生成输出。

### 3.8.1 Softmax 回归的主要思想

在神经网络的最后一层，还是会计算该层的线性部分， $z^{[l]}$ 是最后一层的 $z$ 变量，计算方法是 $z^{[l]}=W^{[l]} a^{[L-1]}+b^{[l]}$

算出了z之后，你需要应用Softmax激活函数，主要思想如下：

1. 计算变量 $t$ ， $t=e^{z^{[l]}}$ ，而 $t$ 适用于每个元素，而在上述例子中， $z^{[l]}$ 的维度是 $4×1$ 的，同样 $t=e^{z^{[l]}}$ 也是 $4×1$ 维的，
2. 使用变量 $a$ 。这里 $a$ 是归一化之后的 $t$。计算公式为 $a^{[l]}=\frac{t}{\sum_{i=1}^{4}t_{i}}$ 。 $\sum_{i=1}^{4}t_{i}$ 代表向量 $t$ 各个元素之和。此时 $a^{[l]}$ 维度同样为 $4×1$ 且元素和为 1，而各个元素所代表的含义就是他们属于某一类别的概率。

Softmax分类器可以代表多种分类之间的线性决策边界。

如果在二分类问题上应用了Softmax，那么输出层 $a^{[L]}$ 将会输出两个数字，假如输出 $0.842$ 和 $0.158$ ，这两个数字加起来等于1，其实它们是冗余的，只需要计算其中一个，所以最终计算那个数字的方式又回到了logistic回归计算单个输出的方式。

### 3.8.2 Softmax 与 hardmax 的对比

hardmax 函数的思想是，观察 $z$ 的元素，然后在 $z$ 中最大元素的位置放上 1 ，其它位置放上 0 。与之相反，Softmax所做的从z到这些概率的映射更为温和

### 3.8.3 Softmax 分类的损失函数

以本节开头的四分类问题为例，Softmax 分类一般用到的损失函数为 $L(\hat{y},y)=-\sum_{i=1}^{4}y_{i}log\hat{y}_{i}$ 。

下面将用单样本的例子方便理解：

1. 假设猫的图片的目标输出为 $y=\begin{bmatrix}0\\ 1\\ 0\\ 0\end{bmatrix}$ 。

2. 实际训练时神经网络的输出为 $\hat{y}=\begin{bmatrix}0.3\\ 0.2\\ 0.1\\ 0.4\end{bmatrix}$ 。这个样本神经网络的表现不佳，这实际上是一只猫，但却只分配到20%是猫的概率，所以在本例中表现不佳。

3. 在这个样本中，因为 $y_1=y_3=y_4=0$，只有 $y_2=1$ ，所以损失函数中所有含有值为0的 $y_i$ 的项都等于0，最后只剩下 $-y_2log\hat{y}_2$ ，即 $-log\hat{y}_2$ 。

    这就意味着，如果你的学习算法试图将损失函数变小，唯一方式就是使 $-log\hat{y}_2$ 变小，要想做到这一点，就需要使 $\hat{y}_2$ 尽可能大，因为这些是概率，所以不可能比1大。

概括来讲，损失函数所做的就是它找到你的训练集中的真实类别，然后试图使该类别相应的概率尽可能地高，如果你熟悉统计学中最大似然估计，这其实就是最大似然估计的一种形式。

而成本函数，即整个训练集损失的总和，就是把训练算法对所有训练样本的预测都加起来，用梯度下降法，使这里的损失最小化。

### 3.8.4 向量化的 Softmax 表示

还是以本节开头为例，在单样本的预测中，输出向量维度为 $4×1$ 。而向量化之后，预测矩阵 Y 最终就是一个 $4×m$ 维矩阵（与输入矩阵 X 类似）。

### 3.8.5 在有Softmax输出层时如何实现梯度下降法

其实初始化反向传播所需要的关键步骤是表达式 $dz^{[l]}=\hat{y}-y$，当有4个分类时，在一般情况下就是C×1，，这是对 $z^{[l]}$ 损失函数的偏导数 $dz^{[l]}=∂J/(∂z^{[l]} )$ 。如果需要从头开始实现Softmax回归或者Softmax分类，就需要记住该公式。

不过对于深度学习框架来说，通常只需要专注于把前向传播，它自己会帮你实现反向传播。

## 3.9 深度学习框架与 Tensorflow

### 3.9.1 深度学习框架

如果从零开始学习了使用Python和NumPy实现深度学习算法，是非常好的。不过，应用更复杂的模型，例如卷积神经网络，或者循环神经网络，或者开始应用很大的模型，对大多数人而言，这样做并不现实。幸运的是，现在有很多好的深度学习框架，可以帮助实现这些模型。利用一些深度学习框架会更加实用，会使你的工作更加有效。

对于选择深度学习框架而言，有以下标准：

1. 便于编程，这既包括神经网络的开发和迭代，还包括为产品进行配置，为了成千上百万，甚至上亿用户的实际使用，取决于你想要做什么。
2. 运行速度，特别是训练大数据集时，一些框架能让你更高效地运行和训练神经网络。
3. 这个框架是否真的开放，它不仅需要开源，而且需要良好的管理。

### 3.9.2 Tensorflow

#### 3.9.2.1 tensorflow 的初步用法

Tensorflow 的损失函数最小化：损失函数为 $J_w=w^2-10w+25=(w-5)^2$

```text
import numpy as np
import tensorflow as tf     # 导入TensorFlow

w = tf.Variable(0, dtype = tf.float32)   # 定义参数w，TensorFlow中用tf.Variable()来定义参数，这里初始化为0。w是我们想要优化的参数，因此将它称为变量。

cost = tf.add(tf.add(w**2, tf.multiply(- 10., w)), 25)     # 我们定义损失函数J
# cost = w**2 -10*w + 25    该过程与上一步功能一样

train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)      # 用0.01的学习率，目标是最小化损失

init = tf.global_variables_initializer()

session = tf.Sessions()     # 这样就开启了一个TensorFlow session。

session.run(init)   # 初始化全局变量

session.run(w)  # 用TensorFlow训练一个变量。

session.run(train)      # 运行一步梯度下降法

print(session.run(w))   # 经过第一次更新参数的 w 的值

for i in range(1000):
    session.run(train)
print(session.run(w))       # 经过1000次训练后得到的w值
```

#### 3.9.2.2 在tensorflow训练时添加训练数据

上面的步骤是针对一个数字进行训练。如果我们要添加自己的训练数据，就需要接下来的函数和方法，如下所示：

```text
x = tf.placeholder(tf.float32,[3,1])    # x 是一个 3×1 维的数组，placeholder函数告诉TensorFlow，你稍后会为x提供数值

cost = x[0][0]*w**2 +x[1][0]*w + x[2][0]

coefficient = np.array([[1.],[-10.],[25.]])     # 该变量是要添加的数据

feed_dict = {x:coefficients}    # 训练时要添加的参数
```

使用这些方法，就可以把`3.9.2.1`中的代码修改为如下代码：

```text
import numpy as np
import tensorflow as tf     # 导入TensorFlow

coefficient = np.array([[1.],[-10.],[25.]])

w = tf.Variable(0, dtype = tf.float32)
x = tf.placeholder(tf.float32,[3,1])
cost = x[0][0]*w**2 +x[1][0]*w + x[2][0]
train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)
init = tf.global_variables_initializer()
session = tf.Sessions()
session.run(init)
session.run(w)

session.run(train, feed_dict = {x: coefficients})
print(session.run(w))

for i in range(1000):
    session.run(train, feed_dict = {x: coefficients})
print(session.run(w))
```

TensorFlow中的placeholder是一个你之后会赋值的变量，这种方式便于把训练数据加入损失方程，当你运行训练迭代时，用`feed_dict`可以使`x = coefficients`。如果你在做mini-batch梯度下降，在每次迭代时，你需要插入不同的mini-batch，那么每次迭代，你就用`feed_dict`来喂入训练集的不同子集，把不同的mini-batch喂入损失函数需要数据的地方。

#### 3.9.2.3 计算图的写法

一般编程的时候，下列两种计算图的使用作用是一样的，但是Python中的with命令更方便清理，以防在执行这个内循环时出现错误或例外。

```text
session = tf.Sessions()
session.run(init)
session.run(w)

with tf.Session() as session:
    session.run(init)
    session.run(w)
```

#### 3.9.2.4 TensorFlow程序的核心

TensorFlow程序的核心是计算损失函数，然后**自动计算出导数**，以及如何最小化损失。

TensorFlow的优点在于，通过用这个计算损失，计算图实现基本的前向传播。之前训练深度神经网络时需要一组前向函数和一组反向函数，而像TensorFlow的编程框架已经内置了必要的反向函数，即便函数非常复杂，它也能自动用反向函数来实现反向传播，再帮你计算导数。所以不需要明确实现反向传播，这是编程框架能帮你变得高效的原因之一。

在编程框架中你可以用一行代码做很多事情，例如，你不想用梯度下降法，而是想用Adam优化器，你只要改变这行代码，就能很快换掉它，换成更好的优化算法。所有现代深度学习编程框架都支持这样的功能，让你很容易就能编写复杂的神经网络。
